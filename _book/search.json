[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modeling Life",
    "section": "",
    "text": "Modeling life\nWelcome to the course Modeling Life.",
    "crumbs": [
      "Course information",
      "Modeling life"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Quarto examples",
    "section": "",
    "text": "1.1 Equations\nHere’s an equation:\n\\[\n\\frac{\\mathrm{d}N}{\\mathrm{d}t} = rN(1 - \\frac{N}{K})\n\\tag{1.1}\\]\nAnd Equation A.1 is a reference to the equation above.",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "intro.html#references",
    "href": "intro.html#references",
    "title": "1  Quarto examples",
    "section": "1.2 References",
    "text": "1.2 References\nSee Knuth (1984) for additional discussion of literate programming.",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "intro.html#syntax-highlighting",
    "href": "intro.html#syntax-highlighting",
    "title": "1  Quarto examples",
    "section": "1.3 Syntax highlighting",
    "text": "1.3 Syntax highlighting\nHere’s some python code:\nimport numpy as np\nnp.random.seed(42)\na = 1 + 2\nb = a + 3\nprint(\"Hello\")",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "intro.html#visualising-data-r",
    "href": "intro.html#visualising-data-r",
    "title": "1  Quarto examples",
    "section": "1.4 Visualising data (R)",
    "text": "1.4 Visualising data (R)\nHere’s an interactive plot generated with R:",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "intro.html#a-youtube-clip",
    "href": "intro.html#a-youtube-clip",
    "title": "1  Quarto examples",
    "section": "1.5 A youtube clip:",
    "text": "1.5 A youtube clip:",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "intro.html#an-iframe-to-a-different-page-e.g.-my-simulations",
    "href": "intro.html#an-iframe-to-a-different-page-e.g.-my-simulations",
    "title": "1  Quarto examples",
    "section": "1.6 An ‘iframe’ to a different page (e.g. my simulations)",
    "text": "1.6 An ‘iframe’ to a different page (e.g. my simulations)\n\n\nMermaid\nDiagrams (Mermaid syntax):\n\n\n\n\n\n\nflowchart TB\nA(Models) --&gt; C(\"Analytical (mathematical)\")\nA --&gt; B(\"Numerical (computational)\")\nB --&gt; F(Individual-based model)\nB --&gt; G(Cellular automaton)\nC --&gt; E(Differential equation)\nC --&gt; D(MAPs)\n\n\n\n\nFigure 1.1: Types of models\n\n\n\n\n\nWhich can be referred to Figure A.1.\n\n\nCallouts\nCall-outs can organise information and highlight important points.\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\n\n\n\nTip 1.1: Cross-Referencing a Tip\n\n\n\nAdd an ID starting with #tip- to reference a tip.\n\n\nSee Tip A.1…\n\n\nHow to format questions/problem sets\n\nExercise 1.1 (Test 1) The equation of any straight line, called a linear equation, can be written as:\n\\[\ny = mx + b\n\\tag{1.2}\\]\nRefer to the equation like this Equation A.2 or like Customlabel A.2.\na. Blabla?\nb. Of blablabla?\n\n\n\nSharing data tables:\n\n\n\n\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "general.html",
    "href": "general.html",
    "title": "2  General course info",
    "section": "",
    "text": "Our names, email addresses, an overview of the course content, learning goals, tips, grading, group formation, usage of Brightspace, materials they need, required attendencee, and feedback is welcome blabla.",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>General course info</span>"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "3  Schedule",
    "section": "",
    "text": "The schedule of the course and important deadlines are outlined below. The course is divided into blabla modules, each with its own set of topics and blabla. The schedule is subject to change, and any updates will be communicated in advance. Blabla.\n(paste below is the schedule of Kwanti/BioMS as an example)",
    "crumbs": [
      "Course information",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Schedule</span>"
    ]
  },
  {
    "objectID": "pattern_intro_text.html",
    "href": "pattern_intro_text.html",
    "title": "4  Pattern formation",
    "section": "",
    "text": "TODO\n\nWrite a short intro on pattern formation part of the practicals.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pattern formation</span>"
    ]
  },
  {
    "objectID": "pattern_practical_1.html",
    "href": "pattern_practical_1.html",
    "title": "5  Practical 1",
    "section": "",
    "text": "TODO",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "pattern_practical_1.html#morphogen-gradients-and-patterning",
    "href": "pattern_practical_1.html#morphogen-gradients-and-patterning",
    "title": "5  Practical 1",
    "section": "5.1 Morphogen Gradients and Patterning",
    "text": "5.1 Morphogen Gradients and Patterning\nIn this practical, we a going to look at how an organism can form segments along its body axis . The mathematical model that we will implement and study is an implementation of the so-called French flag conceptual model first proposed by Lewis Wolpert (Wolpert 1969). It assumes the spatially graded expression of a morphogen “M” that influences the expression of some downstream genes A, B and C. Their expression is often visualized by red, white and blue and the arising pattern resembles the French flag, hence the name (see the power of visualization).\nOne of the most well-studied organisms when it comes to body axis segmentation (although its segmentation mechanism is evolutionary derived and a-typical!) is the development of the fruit fly Drosophila melanogaster. Supporting the ideas of Wolpert, it was found that through tethering maternal Bicoid mRNA to one side of the embryo, Bicoid protein can form a gradient extending along the anterior-posterior axis, with so called gap genes as a first tier in the segmentation hierarchy differentially responding to different Bicoid protein levels (Driever and Nüsslein-Volhard 1988). Later it was found that often at least two opposing morphogen gradients drive downstream gene expression and genes typically respond to multiple inputs.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "pattern_practical_1.html#mathematical-modeling---integrating-multiple-signals",
    "href": "pattern_practical_1.html#mathematical-modeling---integrating-multiple-signals",
    "title": "5  Practical 1",
    "section": "5.2 Mathematical modeling - integrating multiple signals",
    "text": "5.2 Mathematical modeling - integrating multiple signals\nPromotors/enhancers driving gene expression frequently make use of so called OR and AND gates to integrate inputs from different transcription factors. An OR gate can be implemented mathematically with a sum of the effect of the transcription factors, while an AND can be implemented mathematically with a product. Some examples:\n\n\\(\\frac{dX}{dt} = a(\\text{tf1}) + b(\\text{tf2})\\): Gene X is induced by transcription factor 1 and 2 in an OR fashion, either \\(a(\\text{tf1})\\) or \\(b(\\text{tf2})\\) needs to be high to give high transcription of X.\n\\(\\frac{dY}{dt} = a(\\text{tf1})\\cdot b(\\text{tf2})\\): Gene Y is induced by transcription factor 1 and 2 in an AND fashion, both \\(a(\\text{tf1})\\) and \\(b(\\text{tf2})\\), which are being multiplied, need to be high to give high transcription of X.\n\nNote that the shape of \\(a(\\text{tf1})\\) and \\(b(\\text{tf2})\\) (increasing or decreasing function of the transcription factor) determines whether tf1 and tf2 are repressing or activating.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "pattern_practical_1.html#questions",
    "href": "pattern_practical_1.html#questions",
    "title": "5  Practical 1",
    "section": "5.3 Questions",
    "text": "5.3 Questions\nQ1. (Algorithmic thinking) Have a look at the reaction-diffusion equation for the morphogen and the implementation of it in the file morphogengradient_to_segments.py in the reaction_diffusion_step function, as well as at the initialization of the array u. How is this different from the gradient formation modeling we discussed during the lecture? What is done at the terminal boundary in the length direction and why does this make sense? (hint: outcommented we provided code doing essentially the same but not using numpy arrays and hence written in a less compact matter to help you understand what is happening)\nQ2. (Important concept) Play with the morphogen diffusion rate and the morphogen decay rate and describe what happens. What happens in terms of dynamics and steady state if you change both, but the ratio stays the same? Hint: it might help to draw a horizontal line at a certain height to ease comparison.\nQ3 (Biology & mathematical thinking) Next, we are going to introduce the genes A, B and C in the model. We want these genes to be expressed dependent on M, and in the head, trunk and tail respectively, so A on the left, B in the middle and C on the right. Think of what conditions in terms of M should lead to expression of A/B/C. What Hill functions (normal/inverse/any combination) corresponds to those conditions? Write down (pen and paper, not in code) full equations for the genes, do we need any other terms than just Hill functions, would we need specific parameter conditions?\nQ4 (Biology & algorithmic/mathematical thinking) From hereon we assume that the morphogen gradient reaches steady state very quickly, and no longer use the numerical implementation of the diffusion equation and instead work with a superimposed morphogen profile defined by reaction_diffusion_gradient to save time. (Hint: to not call the function any more use # in front of where it is called) Change the simulation loop such that it computes the morphogen gradient once. What type of function is the superimposed morphogen profile and how does this relate to question 2.\nQ5 (Biology & algorithmic/mathematical thinking)\n\nNow create functions to update A, B and C according to your equations from the previous question. You may use the predefined hill and ihill functions that are provided in the code. For simplicity, you may keep most of the parameters the same across genes, but some have to be different to ensure the right location of the genes (see your reasoning to the previous question). (Hint: using array properties to update A/B/C, like in the reaction_diffusion_step function, makes your code run a lot faster than using for-loops)\nAlso make sure that the levels of A, B and C are updated in the simulation loop. (Hint: using array properties to update A/B/C, like in the reaction_diffusion_step function, makes your code run a lot faster than using for-loops)\nNext, ensure A, B and C are visualized in the bottom plot axis (copy and adapt the code for the visualization of M). You can add an extra third axis to the plot to visualize the (French) flag pattern, by getting which of the three genes is maximal at each location with np.argmax(np.array([A, B, C]), axis=0)and turning that into an array of RGB colors of choice.\nDo you get the expected “French flag” pattern? If not, think of why not and improve your equations from previous question, parameters or your code.\n\nQ6 (Biology) At some point in development, the morphogen gradient will disappear, for example in the case of the Drosophila Bicoid gradient because the maternal mRNA is degraded. Predict what will happen to the expression of A,B and C (and hence the French flag pattern) if the morphogen gradient disappears over time and assume A, B, and C are regulated by our equations (first try think about this without actually simulating this).\nQ7 (Algorithmic/mathematical thinking) Now write the code in reaction_diffusion_gradient that updates the morphogen concentration, such that after the time point A, B and C have gotten close to equilibrium, the morphogen gradient gradually disappears. Adapt the simulation loop where necessary and run your code: was your prediction on A/B/C from the previous question correct? Why/why not? Hint: you might need to increase the duration of your simulation, especially if it takes a long time for A, B and C to reach equilibrium (or you can change the parameters to speed things up by using same production/degradation rate ratio yet higher absolute values of the individual parameters).\nQ8 Biological & mathematical thinking A, B and C cannot remain in a stable pattern if they are only influenced by M. How can we stabilize the pattern in absence of M? Test your ideas by creating new update functions for A, B and C and let these new ‘rules’ kick in at the same time when M starts to decline. Again, you may find Hill functions useful and perhaps also the before/after switch time structure used in reaction_diffusion_gradient for M. (Hint: think about how the genes should affect each other, and assume that in this new phase, when genes have already been initialized in absence of repression the genes will be expressed). Can you maintain the expression domains of A, B and C and does their shape change?\nQ9 (Biology & algorithmic/mathematical thinking) A sudden switch from phase 1 (stable M gradient) to phase 2 (decaying M gradient) resulting in the genes following different differential equations is biologically implausible. In reality, genes have complex promotors and enhancers integrating different inputs that arise in different developmental stages. Try to come up with one integrated expression for each gene, incorporating simultaneous input from the morphogen gradient and the other genes. Create new update functions for A/B/C and test your ideas. Can you get a stable pattern before and after the decline in M? A couple of things you could consider: a. Think of how positively and negatively M regulated expression behave once the gradient starts declining: what is the best way to combine (AND/OR) that with the regulation by the genes? a. Consider splitting up the M regulated expression of middle gene B into a positive and negatively regulated morphogen part before integrating the other genes inputs. a. It is also possible to give certain genes a bit of a constant boost to prevent their takeover by other genes due to timing issues\nQ10. Biology & algorithmic/mathematical thinking Write code to get noise in the morphogen gradient, both in its steady state and decaying phase. During which phase do the expression domains of A, B and C suffer more from the noise. Explain why? How could we make the system more robust in a manner that is also likely occurring in nature?\n\nExtra questions for if you’re done early/ for master students. These questions need not be made in the order they are provided, you can choose what you would like to investigate.\nQ11 (Biological thinking) Play with the size of the domain to see what happens to the gene expression domains. What would this mean for an organism?\nQ12 (Biological & algorithmic thinking) Various mechanisms have been proposed to ensure that the domains of the morphogen controlled genes scale with the size of the domain. One proposed mechanism suggests the existence of an also diffusible “expander” molecule which expression is repressed by the morphogen but which itself either represses the degradation of the morphogen or enhances its diffusion (see e.g. https://www.pnas.org/doi/full/10.1073/pnas.0912734107 and https://onlinelibrary.wiley.com/doi/10.1111/dgd.12337).\nFor the expander we can write:\n\\[\n∂E/∂t=p K^h/(K^h+M^h )-dE+D_E ∆E\n\\]\nAssume E reduces degradation of M (easier to implement than enhancement of diffusion) and study the effect of scaling. (Hint, vary the size of the domain in the length direction but plot domains as a function of relative instead of absolute domain size to compare domain sizes).\nQ13 (Algorithmic thinking) In b, we can also implement other boundary conditions, especially for the right boundary. What happens to the profile if we make a no-flux boundary by copying the value at n-2 to n-1? And what if we set it to a sink (force concentration to zero)?\nQ14 From question 4 onwards, how do things change if we do not assume a quasi-steady-state for the morphogen gradient (i.e. keep the morphogen dynamics instead of replacing it by the superimposed exponential)? How would you implement a disappearing gradient and how does it shape change the outcomes of the flag?\nQ15 Implement your solution to make the system more robust for noise from question 10. Did it work?",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "pattern_practical_1.html#python-code",
    "href": "pattern_practical_1.html#python-code",
    "title": "5  Practical 1",
    "section": "5.4 Python code",
    "text": "5.4 Python code\n\n\n\n\n\n\nStarting code for this practical\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\nLx = 40.0  # Length of the domain in x in microm\nLy = 10.0  # Length of the domain in y in microm\nT = 200  # Total time in seconds\ndx = 0.5  # Grid spacing in x\ndt = 0.1  # Time step\nnx = int(Lx/dx)+2  # Number of grid points in x + padding grid points\nny = int(Ly/dx)+2  # Number of grid points in y + padding grid points\n# Padding grid points to account for boundary conditions\nnt = int(T/dt)  # Number of time steps\nD = 0.4  # Diffusion coefficient in mm^2/s\ndecayM =0.01 # Decay rate in 1/s\n\n\n# Parameters for A, B, C\n... # TODO create parameters for A, B, C as needed in Q5\n\n# Stability criterion\nif D * dt / dx**2 &gt; 0.5:\n    raise ValueError(\"Stability criterion not met\")\n\n# Initial condition\nu = np.zeros((nx, ny))\nu[0, :] = 100\n\n# A, B and C are required for later exercises.\nA = np.zeros((nx, ny))\nB = np.zeros((nx, ny))\nC = np.zeros((nx, ny))\n\n# Reaction-diffusion equation\ndef reaction_diffusion_step(u, D, dt, dx, decay):\n    un = u.copy()\n    u[1:-1, 1:-1] = un[1:-1, 1:-1] +  D *dt / dx**2 * (un[2:, 1:-1] + un[:-2, 1:-1] + \\\n                    un[1:-1, 2:]  + un[1:-1, :-2] - 4 * un[1:-1, 1:-1]) - \\\n                    decay * un[1:-1, 1:-1] * dt\n    ## for loop version to understand the equation\n    # for i in range(1, nx-1):\n    #     for j in range(1, ny-1):\n    #         u[i, j] = (un[i, j] +\n    #                    D * dt / dx**2 * (un[i+1, j] + un[i-1, j] - 2 * un[i, j] +\n    #                    un[i, j+1] + un[i, j-1] - 4 * un[i, j]) -\n    #                    decay * un[i, j] * dt)\n    \n\n    #boundary conditions\n    u[-1, :] = (u[-2, :]/u[-3, :])*u[-2, :]  if sum(u[-3, :]) != 0 else np.zeros(ny)\n    u[:, 0] = u[:, 1]\n    u[:, -1] = u[:, -2]\n\n    return u\n\ndef reaction_diffusion_gradient(t, u, D, dx, decay, switch_time = None, noise = False):\n    '''\n    Function to create a gradient in the u array that could decay after a certain time.\n    t: current time step\n    u: array to create the gradient in\n    D: diffusion coefficient\n    dx: grid spacing\n    decay: decay rate\n    switch_time: time step after which the gradient decays. If no switch is desired, set to None\n    noise: whether to add noise to the gradient\n    '''\n    # TODO for student: write code for the noise and the switch.\n    added_noise = np.zeros_like(u)  # Initialize noise array\n    if noise:\n        ...  # TODO: add noise generation code here for Q10\n    \n    if switch_time is None or t &lt;= switch_time:\n        # define a exponential decay gradient over the array in the x direction with numpy array operations using the index\n        for i in range(u.shape[0]):\n            u[i, :] = np.maximum(100 * np.exp(-i*dx/np.sqrt(D/decay))+added_noise[i, :], 0)\n        return u\n    if t &gt; switch_time:\n        ...# TODO Q7: implement a different gradient that decays over time, otherwise return the original u array\n        return u\n    # In all other cases, return the original u array        \n    return u\n\ndef hill(x, Km, pow):\n    \"\"\"Hill function for the reaction kinetics.\"\"\"\n    return (x**pow) / (Km**pow + x**pow) \n\ndef ihill(y, Km, pow):\n    \"\"\"Inverse Hill function for the reaction kinetics.\"\"\"\n    return( (Km**pow) / (y **pow  + Km**pow))\n\n# TODO for student: write update functions for A, B, C as needed in Q5\n\n\n# initilize figure and axes for plotting\n# TODO for student: Add a new axis for the ABC flag visualization as suggested in Q5\nfig, (ax_M, ax_lines) = plt.subplots(2, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]})  # Make the first graph 3 times the height of the second\n\n# Time-stepping simulation loop\nfor n in range(nt):\n    # Update all variables\n    u = reaction_diffusion_step(u, D, dt, dx, decayM)\n    # TODO for student: use precomputed gradient, update A, B, C as needed in Q5\n    \n    if n == 0:  # Initial plot\n        imshow_M_plot = ax_M.imshow(u.T, cmap='viridis', origin='lower', aspect='auto')\n        ax_M.set_title(f\"Time: {n*dt}\")\n        ax_M.set_xlabel('x direction')\n        ax_M.set_ylabel('y direction')\n        ax_M.set_xticks([])\n        ax_M.set_yticks([])\n\n        # Plot the concentration at a specific y index (e.g., y=2)    \n        line_plot = ax_lines.plot([x*dx for x in range(nx)], u[:, 2], label='M', color='green')\n        # TODO: Add lines for A, B, C as needed in Q5\n\n        \n        ax_lines.legend(loc='upper right')\n        ax_lines.set_ylim(0, 100)\n        ax_lines.tick_params(axis='y')\n        ax_lines.set_xlim(0, dx*nx)\n        ax_lines.set_xlabel('x')\n        ax_lines.set_ylabel('Concentration at y=2')\n        ax_lines.tick_params(axis='x')\n\n    if n % 20 == 0:  # Update plot every so many time steps\n        #update the imshow M plot with the new data\n        imshow_M_plot.set_data(u.T)\n        ax_M.set_title(f\"Time: {n*dt}\")\n            \n        # Update the line plots with new data\n        line_plot[0].set_ydata(u[:, 2])\n        # TODO: Update A, B, C line plots as needed in Q5\n\n    plt.pause(0.001)  # Pause to refresh the plot\n\n# And keep the last plot open\n# plt.show()\n\n# Or close the plot window when done\nplt.close(fig)",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "pattern_practical_1.html#relevant-literature-further-reading",
    "href": "pattern_practical_1.html#relevant-literature-further-reading",
    "title": "5  Practical 1",
    "section": "5.5 Relevant literature / further reading",
    "text": "5.5 Relevant literature / further reading\nhttps://www.nature.com/articles/ncomms6077\nDagmar Iber group, scaling from non-steady state dynamics and uniform growth\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC3109599/\nhttps://www.nature.com/articles/ncomms7679\nBicoid gradient: larger eggs get more Bicoid mRNA so higher production rate, when it scales with volume this helps scale the gradient\nhttps://onlinelibrary.wiley.com/doi/10.1111/dgd.12337\nhttps://www.pnas.org/doi/abs/10.1073/pnas.0912734107\nExpansion repression model\nChordin, Bmp, Sizzled\nChordin represses Bmp which induces Sizzled (which has low decay rate), yet Sizzled reduces Chordin decay\nChordin is morphogen\nSizzled is expander (by reducing decay of morphogen)\n\n\n\n\nDriever, Wolfgang, and Christiane Nüsslein-Volhard. 1988. “The Bicoid Protein Determines Position in the Drosophila Embryo in a Concentration-Dependent Manner.” Cell 54 (1): 95–104.\n\n\nWolpert, Lewis. 1969. “Positional Information and the Spatial Pattern of Cellular Differentiation.” Journal of Theoretical Biology 25 (1): 1–47.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "pattern_practical_2.html",
    "href": "pattern_practical_2.html",
    "title": "6  Practical 2",
    "section": "",
    "text": "TODO",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "pattern_practical_2.html#turing-patterns-repetitive-patterning",
    "href": "pattern_practical_2.html#turing-patterns-repetitive-patterning",
    "title": "6  Practical 2",
    "section": "6.1 Turing patterns, repetitive patterning",
    "text": "6.1 Turing patterns, repetitive patterning\nConceptual thinking: The model proposed by Raspopovic et al. for generating Turing patterns underlying limb bone modeling consists of 3 instead of 2 interacting variables. Simplify the given interaction scheme and diffusion constants to a 2D system to identify the relevant Turing constraints\nAlgorithmic thinking: Compare the code used here to implement diffusion (lines …) with the code used in the exercise on the French Flag. What do you think this code is doing? What kind of boundary conditions do you think are implemented\nBiology: First we are going to work with a code simulating the model in a 2D constant tissue, this can be considered as a petri dish in which the mesenchymal cells have been plated with the correct chemicals to undergo bone formation (Fig .. in the paper). Play with the reaction parameters and diffusion constants to study their effects on the wavelength of the patterns\nBiology: Now we are going to add tissue growth in the proximo-distal (body to limb) direction. Growth is controlled by a growth rate vi. Play with this rate and study what happens. Explain why this happens.\nIf the growth rate is large enough the induced anisotropy causes the orientation of Turing stripes along the growth axis. This can be understood from the directional expansion of the growth and hence diffusion domain, with the activator mostly spreading in this growth direction, leading to stripe formation.\nBiology: In reality the paddle shaped limb growth in both the proximo-distal and anterior-posterior direction, implemented with growth rates vi and vj. Play with the relative size of these growth rates and study what happens. Also study the order of appearance of digits and how this compares to the experimental data. Does the pattern fully resemble experimental observations?\nTo not loose the anisotropy vi&gt;&gt;vj. Middle digits appear first and as expansion occurs in the anterior-posterior plane more digits appear. No, digits do not come closer together at proximal end\nBiology: In reality digits are patterned further apart at the distal end then at the proximal end, where they need to converge on a hand and wrist. This implies that the wavelength of the Turing pattern should not be constant. If all is well you found that the k7 and k4 parameters impact the wavelength of the Turing pattern. The authors speculate that the FGF and Hox gene gradients observed in the limb bud excert an effect on the Sox9-BMP-Wnt patterning module through these parameters. Implement a gradient of increasing k7 and decreasing k4 from the proximal to the distal end of the growing limb and try if you can get closer to a realistic limb patterning.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "pattern_practical_2.html#biology-polydactyly-evolution",
    "href": "pattern_practical_2.html#biology-polydactyly-evolution",
    "title": "6  Practical 2",
    "section": "6.2 Biology: polydactyly? Evolution?",
    "text": "6.2 Biology: polydactyly? Evolution?",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "pattern_practical_2.html#python-code",
    "href": "pattern_practical_2.html#python-code",
    "title": "6  Practical 2",
    "section": "6.3 Python code",
    "text": "6.3 Python code\n\n\n\n\n\n\nStarting code for this practical\n\n\n\n\n\nThere are several sources for this practical.\n…\n\n\n\nIf two days: phyllotaxis model.\nGood to do after clock and wavefront a general overview:\nWhat happens if more growth/tissue in\n-gradient (rear extends if no scaling)\n-Turing (more stripes)\n-clock and wavefront (bigger stripes)",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html",
    "href": "pattern_practical_3.html",
    "title": "7  Practical 3",
    "section": "",
    "text": "7.1 Clock-and-wavefront patterning",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#clock-and-wavefront-patterning",
    "href": "pattern_practical_3.html#clock-and-wavefront-patterning",
    "title": "7  Practical 3",
    "section": "",
    "text": "TODO\n\nMove the answers to a separate page\nLinks to github for the code",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#goal-of-the-tutorial",
    "href": "pattern_practical_3.html#goal-of-the-tutorial",
    "title": "7  Practical 3",
    "section": "7.2 Goal of the tutorial:",
    "text": "7.2 Goal of the tutorial:\nIn this tutorial you will look at gradient formation and patterning using different mechanisms than you have seen previously. We will model the so called clock-and-wavefront pattern, which stems from oscillations in gene and gene products and results in a regularly striped pattern in a growing tissue.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#the-model-system",
    "href": "pattern_practical_3.html#the-model-system",
    "title": "7  Practical 3",
    "section": "7.3 The model system",
    "text": "7.3 The model system\nThe clock-and-wavefront model is an important model in describing somitogenesis. In this process early in embryo development, the somites, a precursor tissue for the vertebrae and other tissues later in development, are formed from the pre-somitic mesoderm. This mesodorm extends on the posterior end by growth, and the somites bud off periodically at the anterior end in the order of a couple of weeks (in humans).\nKey players in this model system are the protein FGF (fibroblast growth factor), and many genes and gene products that have an oscillatory pattern that will determine cell fate. However, for this tutorial, we simplify this to a single pair of gene mRNA and product, denoted with \\(m\\) and \\(p\\) for short.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#programming-with-classes",
    "href": "pattern_practical_3.html#programming-with-classes",
    "title": "7  Practical 3",
    "section": "7.4 Programming with classes",
    "text": "7.4 Programming with classes\nBecause we are going to make a more complex model with a tissue existing of multiple cells, and each cell having its own concentrations of FGF, \\(m\\) and \\(p\\), we are going to use Classes in our code. You have been using Classes already: the data types such as int, str and bool have their own class, and the str class has many methods (=functions working on that class) defined, such as \"hello world\".upper(), but it is also possible to create custom classes. With classes, you can easily make objects, which is part of the object-oriented programming paradigm.\nToday, we are going to use classes for the different levels of our model: 1) tissue, 2) cell, 3) \\(m\\) & \\(p\\) clock and 4) the plotting. By using classes, we can separate things that happen on a tissue/cellular/clock scale, and seperate the model from the visualization of it. You will first work with 1 & 2 & 4, then 3 on its own and then combine all four yourself into one model.\nImportant concepts when working with classes are\n\nClass versus instance\nDefining the __init__ method and other methods\nClass attributes and using the keyword self\n\nThis tutorial should be doable without an extensive knowledge of classes as there are plenty of examples to copy-paste from, but feel free to read up on these concepts here at this online tutorial",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#relevant-literature",
    "href": "pattern_practical_3.html#relevant-literature",
    "title": "7  Practical 3",
    "section": "7.5 Relevant literature",
    "text": "7.5 Relevant literature\nIf you want to know more about the model system and previous models, have a look at the following (after the tutorial):\nLewis (2003) _Autoinhibition with Transcriptional Delay A Simple Mechanism for the Zebrafish Somitogenesis Oscillator",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#exercises",
    "href": "pattern_practical_3.html#exercises",
    "title": "7  Practical 3",
    "section": "7.6 Exercises",
    "text": "7.6 Exercises\n\nIn practical 1 we saw how gradients can be created through local production, diffusion and decay. However, other mechanisms for gradient formation are possible, such as cell lineage transport. Here we work with a model for the FGF gradient (fgfgradientfromgrowth.py) where only the rightmost/posterior cell produces FGF and grows, and in which cells upon division inherit this FGF from their mother cell. Play with the model by varying the decay rate of FGF and the division rate of the cells. How does this affect the gradient?\n\n\nAnswer If growth rate goes up cell volumes increase faster, causing more dilution of FGF and hence a lower maximum of the gradient as due to the stable protein quite some time is needed to compensate for this decrease by more production, at the same time the gradient is less steep as cell division follow up faster and hence less time has passed and less day has taken place. If decay rate goes up, maximum goes down but gradient become steeper and shorter as for same time between divisions more decay takes place\n\n\nConceptual thinking When would this type of gradient formation be more applicable than the earlier studied production, diffusion, decay type of gradient formation? Compare how this model is built-up to a production/diffusion/decay gradient formation model.\n\nAnswer Diffusion slow, degradation slow. In other words, a mostly stable, immobile compound.\n\nMathematics Let us now move to the other half of the clock and wavefront model, the clock part (clock.py), in which we implemented one of the earliest models for the somitogenesis oscillator from Lewis (2003) which models a gene that codes for a mRNA (\\(m\\)) that encodes a protein (\\(p\\)) that acts as a repressive transcription factor of this same gene. In class we discussed how for oscillations negative feedbacks, delays and non-linearity are important. Examine the code to find the differential equations governing this model and determine the negative feedback, delay and non-linearities in them.\n\n\nAnswer Non-linearity is in saturation function with power n, negative feedback is because affects own expression negatively, delay is here modeled explicitly through a special delay type differential equation\n\n\nBiology Play with the parameters of the model. How does the delay (tau/ \\(\\tau\\)) affect oscillations? &gt; Answer longer period (lower frequency) and higher amplitude. Remember how in class we discussed how removing introns reduced delays and affected oscillator period.\nAlgorithmic thinking In the file rolling_clock.py, there is a different implementation of the clock. Compare the two files and find out how they differ. What benefits for studying the model does clock.py have over rolling_clock.py and vice versa? Ignore the added functions __copy__ and set_tau in this comparison. Some differences become clearer when you run the code too.\n\nAnswer The rolling clock only remembers a certain time window of the clock state, namely as long as needs to be remembered plus some buffer for when the clock’s tau changes. A drawback is that not all history is memorized, but it could still be stored to a file. A big win is clear when we run the code and see that it is much faster, especially at later time points.\n\nNext, we will combine the clock and FGF wavefront into a single model. For this, we offer two options of this exercise: A. reading and interpreting existing code from the file clockplusfgf.py, or B. write your own code to combine the two.\n\nRead and interpret existing code: Read the code of clockplusfgf.py and try to understand the assumptions from this model implementation by answering the following questions:\n\nEach cell has its own clock. What clock states is the tissue initialized with? And what clock states do newly divided cells get?\nThe FGF wavefront affects tau: what function is used for that? What are your expectations for the effect of the FGF wavefront on the cells’ clocks?\nDoes growth affect the clock state?\nWhat is your opinion on the assumptions from the three questions? &gt; Answer &gt; 1. The cells are initialized with the same state, namely the default with &gt; m=0 and p=0, and all clock parameters set to one defined in the file. &gt; Newly divided cells get the same clock as the original cell, so we get &gt; two exact copies. &gt; 2. The function is \\[\\tau_\\text{cell}=\\tau_\\text{model}(1+0.5\\frac{100-\\text{FGF}\\_\\text{cell}}{100}),\\] &gt; where \\(\\tau_\\text{cell}\\) is the cell’s new \\(tau\\) and \\(\\tau_\\text{model}\\) the general “model” one’s. &gt; So, we would expect tau to become larger, i.e., the clock to become slower as the FGF wavefront &gt; decays the further to the left we get. &gt; 3. No, there is currently no dilution from \\(m\\) or \\(p\\) from growth. &gt; 4. If we start with few cells that are likely also each other’s sister cells, &gt; the assumption of the same, or at least similar clock states is plausible. &gt; Same for cell division assuming the molecules get evenly distributed. &gt; The current function of FGF on \\(\\tau\\) is imposed, but the idea of slowing down is from &gt; experimental observations. &gt; We could argue about the effect of growth on the clock state, but only few cells are &gt; dividing, so including growth in there would have only a limited effect (but feel free &gt; to test this!).\n\nProgramming As to not spoil the beans to students not wanting to code the model extension, since the hints for programming may answer above questions, please see instructions for implementing it yourself at the end of this tutorial.\n\nBiology With the existing model, or your own model working, describe how this model behaves. Do we get stable somites?\n\nAnswer we get waves of oscillations moving from left to right with increasing amplitudes. Not yet conversion to a stable stripe pattern\n\nBiology & Programming What is still missing is a means to transform the temporal oscillations in the posterior of the tissue into a spatial pattern in the anterior. Now, let’s implement a model that allows for fixation of the somite states.\n\nWe will add an extra ‘memory’ molecule M inside the cell that will be produced depending on the values of FGF and the clock.. To do so add a new attribute to the cell Class that will contain the value of a memory molecule. Also, upon division, let cells inherit the memory value from the mother cell.\nChange the run_clocks function by creating two conditions:\n\nIf the fgf level is between some upper and some lower bound, the clock is updated and simulated after the memory value is updated according to this formula: \\[\\frac{dM}{dt}=c\\max\\left(\\frac{p^4}{h_p^4+p^4}, \\frac{M^4}{h_M^4+M^4}\\right)-\\delta M.\\] Add the new memory parameters as global parameters at the top of the file. For starters, you can give them the following values:\n\n\\(\\text{FGF upper bound}=10\\)\n\\(\\text{FGF lower bound}=9.75\\)\n\\(c=0.01\\)\n\\(h_p=8.5\\)\n\\(h_M=0.5\\)\n\\(\\delta=0.01\\)\n\nOtherwise, the clock is updated and simulated as normal, and nothing changes with the memory molecule of the cell\n\nTo visualize the memory, follow the same procedure as for visualizing the fgf and p values: put in a string referring to the new attribute you created for the molecule in step 1.\n\nBiology Do you get stable somite formation on the left/anterior of the tissue? Is it a regular pattern of somites? What happens if the requirement for updating \\(M\\) is only that FGF should be below a certain value? What happens if the equation for \\(\\frac{dM}{dt}\\) only depends on \\(p\\) and not \\(M\\) itself.\n\n\nAnswer They should get somite patterns that are stable, but not necessarily regular. If only one threshold all goes to high state, because eventually all go through all phases, you need to memorize who was within a limited time/space window in a particular state. If only P dependent M is activated but does not memorize so it will be just as unstable as P before.\n\n\nBiology Both zebrafish and mice are common model organisms, so we know a lot about the biological parameters of their somitogenesis. See the following list:\n\n\n\n\n\n\n\n\n\n\nParameter\nZebrafish\nReference\nMouse\nReference\n\n\n\n\nDuration of somitogenesis\n18 h\n(a)\n5 days\n(b)\n\n\nNumber of somites\n~30\n(a)\n65\n(c)\n\n\nSomite size\n50 micron / 30 micron\n(d) (a)\n120 micron\n(c)\n\n\nCells per somite\n~5 cell in diameter\n(a)\n5-11 (estimated from total cell size in 3D, ranging 1 order of magnitude)\n(c)\n\n\nClock period\n25 min /30 min\n(d) / (e) / (f)\n2-3 h\n(e)\n\n\n\nFrom these parameters, you can derive a number of desired model inputs/outcomes:\n\nThe total size of the tissue at the end of somitogenesis\nThe size of a cell\nSpeed of division\n\nUse the model and try to find suitable model parameters to recreate the development of both zebrafish and mice: is this model able to describe both of these processes? I.e., is this model able to deal with the scale differences between zebrafish and mice?\nA couple of notes:\n\nYou don’t have to exactly recreate the biological parameter with 100% precision, except for the number of segments/somites, although it can be a fun challenge to get a complete match.\nYou might want to adapt your plotting timestep to have sufficient but not too many plot updates in one simulation.\nYou can test the clock parameters separately with the clock.py/rolling_clock.py script. Don’t forget that FGF has an effect on tau!",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#further-open-questions",
    "href": "pattern_practical_3.html#further-open-questions",
    "title": "7  Practical 3",
    "section": "7.7 Further (open) questions",
    "text": "7.7 Further (open) questions\nThe model currently has a number of assumptions that we can question. Feel free to explore any of these further open questions and study how it effects the outcome of the model:\n\nWhat if the relationship between FGF and tau is shaped differently? For instance, if the clock runs faster on the left/anterior than on the right/posterior?\nWhat if the clock state of a daughter cell is started fresh rather than being a copy from the mother cell?\nWhat if the clock \\(m\\) and \\(p\\) are diluted by growth?\nWhat if tau is unaffected by FGF: can we still get somites fixed in place?",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#references-for-biological-parameters",
    "href": "pattern_practical_3.html#references-for-biological-parameters",
    "title": "7  Practical 3",
    "section": "7.8 References for biological parameters:",
    "text": "7.8 References for biological parameters:\n\nhttps://anatomypubs.onlinelibrary.wiley.com/doi/10.1002/1097-0177(2000)9999:9999%3C::AID-DVDY1065%3E3.0.CO;2-A\nhttps://doi.org/10.1016/j.gde.2012.05.004\nhttps://doi.org/10.1242/dev.65.Supplement.103\nhttps://doi.org/10.1242/dev.161257\nhttps://doi.org/10.3389/fcell.2022.944016\nhttps://www.sciencedirect.com/science/article/pii/S0079610718300178",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_practical_3.html#combining-the-clock-and-fgf-wavefront-model---programming-instructions",
    "href": "pattern_practical_3.html#combining-the-clock-and-fgf-wavefront-model---programming-instructions",
    "title": "7  Practical 3",
    "section": "7.9 Combining the clock and FGF wavefront model - programming instructions",
    "text": "7.9 Combining the clock and FGF wavefront model - programming instructions\nLet us now combine the (rolling) clock and the wavefront, and assume that the FGF wavefront affects tau such that as FGF levels drop tau goes up and oscillations slow. Here are some tips and hints to help you along the way:\n\nTry implementing things in steps and run your code in between steps: this is easier to debug than changing everything in one go.\nUse the file rolling_clock.py to import the clock class from. Make sure that every cell gets initialized with a clock by adding a clock as a cell Class attribute.\nOf course, we must not forget that a cell inherits the clock from its mother. Use the __copy__ method from the clock Class to set the clock of the freshly divided daughter cell the same as the mother’s.\nThere are many ways that FGF could affect tau. For this tutorial, stick to the following relationship: \\[\\tau_\\text{cell}=\\tau_\\text{model}(1+0.5\\frac{100-\\text{FGF}\\_\\text{cell}}{100}),\\] where \\(\\tau_\\text{cell}\\) is the tau of a specific cell, and \\(\\tau_\\text{model}\\) is a global tau set as a model parameter. To implement this, create a method update_clock for the cell Class, that uses the clock Class’s set_tau method to update the clock of the cell.\nMake a method in the tissue class called run_clocks that simulates the clock of every cell in the tissue. Use the Clock’s simulate method. For simplicity, we assume that growth does not affect the concentrations of \\(m\\) and \\(p\\).\nMake sure that the tissue method run_clocks also updates the clock of the cell, and that the simulate_development function also lets the clocks run.\nVisualize the p values of every cell. You can reuse the existing visualisation methods initialize_axis_cell_data and update_plot_cell_data from graphics.py, but now let them display p values instead of fgf values. You can give the name of the attribute as a string to the initialize_axis_cell_data function, so something like clock.p_values[-1] instead of fgf might already work depending on your exact implementation of the clock.\nOnce you’re done, check if your model behaves as it should with the teacher/assistant or the file clockplusfgf.py directly.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "pattern_answers.html",
    "href": "pattern_answers.html",
    "title": "8  Answers",
    "section": "",
    "text": "8.1 Answers partical 1\nAnswer Q1\nAn important difference relative to the lecture is that instead of implementing a production term at the x=0 position, we instead fixed the concentration of u at x=0 at 100 and have nowhere a production term. This implies that we assume that production is very high and different D and d values have negligible effects on the level at x=0. The advantage of this approach is that we can easily study what different D and d does, as it only affects the shape of the gradient but not the maximum.\nInstead of using if/else to check for boundary conditions, we only compute the Laplacian in the inner, non-boundary points. For the x=0 boundary we already set a constant value. For y=0 and y=n−1 we copy the values from y=1 and y=n−2 as the patterning is identical in that direction. For x=n−1 we use a special approach: if n−3=0 we assume it is zero; otherwise, we calculate the ratio of x at n−2 and n−3 to approximate the decay and multiply this with the value at x=n−2 to estimate x at n−1. Simply copying x at n−2 would add matter to the system and prevent the gradient from reaching a steady state.\nAnswer Q2\nThe imposed morphogen profile is an exponential gradient. The negative sign indicates a decline, the term i·dx converts the grid index to spatial distance, and the division by √(D/d) ensures that if i·dx = λ = √(D/d), we have e⁻¹ = 1/e, meaning an e-fold decay — as expected for a steady-state diffusion gradient.\nAnswer Q3\nThe relevant concept is the diffusion length, √(D/d). It is the ratio between these parameters that determines the characteristic length scale λ over which the morphogen concentration decays e-fold. Changing both D and d while keeping the ratio constant preserves the shape of the steady-state gradient, but faster rates lead to a quicker approach to steady state.\nAnswer Q4\ndA/dt = normal hill(M) − decay term\ndB/dt = normal hill(M) × inverse hill(M) − decay term\ndC/dt = inverse hill(M) − decay term\nFurthermore, kA = kB₁ &lt; kB₂ &lt; kC to ensure the switches happen at the correct positions.\nAnswer Q5\nGene C needs to be induced by low M and repressed by high M. Together with kA = kB₁ &lt; kB₂ &lt; kC, this generates the expected “French flag” pattern with distinct domains for A, B, and C.\nAnswer Q6\nAs M decays, A and B will no longer be activated and C will no longer be repressed, leading to a takeover by C. Consequently, the French flag pattern disappears.\nAnswer Q7\nWhen the morphogen gradient gradually disappears, C always takes over. This confirms the prediction that as M declines, C dominates due to loss of repression on its expression domain.\nAnswer Q8\nAs M decays, A and B lose activation and C loses repression, again leading to takeover by C. They will find that mutual repression with only one neighboring gene is insufficient — stability requires each gene to repress both others (A repressed by B and C, B by A and C, and C by A and B). This maintains A at the beginning, B in the middle, and C at the end, although expression domains become sharper.\nAnswer Q9\nAchieving a smooth transition between the stable and decaying phases of M requires integrated gene regulation.\nSuch combined formulations better represent biological promoter logic and yield stability before and after the morphogen decline.\nAnswer Q10\nNoise has the strongest effect during the initial phase when morphogen levels dominate, since mutual repression has not yet stabilized the pattern. As gene expression becomes established and M decays, the system becomes more robust.\nDiffusion of A, B, and C in the lateral direction would further smooth out local variations and enhance robustness (not implemented in the current version).\nAnswer Q11 (Extra)\nIf the domain expands, the C domain enlarges; if the domain contracts, the C domain disappears. In biological terms, this would mean losing or gaining posterior body regions (“butt” part).\nAnswer Q12 (Extra)\nIntroducing a diffusible “expander” molecule E that is repressed by M but reduces M’s degradation can create scaling of gene domains with overall tissue size. For example:\n∂E/∂t = p·Kʰ/(Kʰ + Mʰ) − dE + D_E·ΔE\nVarying the domain length while plotting results against relative position (x/L) should show improved scaling of A/B/C domains.\nAnswer Q13 (Extra)\nCopying n−2 to n−1 introduces artificial accumulation at the boundary and prevents steady state. Setting it to zero (sink) has not been tested but is expected to lower concentrations and possibly speed up stabilization.\nAnswer Q14 (Extra)\nWithout assuming quasi–steady-state for M, one can simulate a dynamic morphogen gradient by allowing production at x=0 to decay over time or by letting the exponential decline parameter itself vary. This will likely lead to different transient shapes and small shifts in A/B/C domains compared to a static exponential.\nAnswer Q15 (Extra)\nImplementing diffusion of A, B, and C is expected to smooth out local noise effects and enhance robustness of the spatial pattern, consistent with what is observed in natural systems.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Answers</span>"
    ]
  },
  {
    "objectID": "pattern_answers.html#answers-partical-1",
    "href": "pattern_answers.html#answers-partical-1",
    "title": "8  Answers",
    "section": "",
    "text": "For genes (or parts thereof) that are positively dependent on M, use an OR gate (sum): this keeps them on once M disappears, provided mutual repressors are absent.\nFor genes (or parts thereof) that are negatively dependent on M, use an AND gate (product): this prevents them from expanding when M vanishes, requiring both low M and absence of repression.",
    "crumbs": [
      "I) Pattern formation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Answers</span>"
    ]
  },
  {
    "objectID": "morpho_intro_text.html",
    "href": "morpho_intro_text.html",
    "title": "9  What is morphogenesis?",
    "section": "",
    "text": "TODO\n\nWrite a brief intro to the morphogenesis practicals",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>What is morphogenesis?</span>"
    ]
  },
  {
    "objectID": "morpho_practical_1.html",
    "href": "morpho_practical_1.html",
    "title": "10  Practical 4",
    "section": "",
    "text": "10.1 Gene regulation in time\nIn this practical you will get hands on experience into making gene regulatory networks models. First you will practice how to encode regulatory interactions into ordinary differential equations and logical rules. Next you will study how many interactions produce self-sustained activity configurations (attractors) in a Boolean network model. Lastly, you will learn how to predict the genes that cause cell fate transitions (attractor changes).\nToday we will use the following python file: circuitsfunctions.py. In this file you will find the code of the functions we use throughout the practical, have a quick look at it. Look at the name of the functions, inputs and outputs.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Practical 4</span>"
    ]
  },
  {
    "objectID": "morpho_practical_1.html#part-i---encoding-regulatory-interactions",
    "href": "morpho_practical_1.html#part-i---encoding-regulatory-interactions",
    "title": "10  Practical 4",
    "section": "10.2 Part I - Encoding regulatory interactions",
    "text": "10.2 Part I - Encoding regulatory interactions\nOpen Boolean_practical.py and familiarize yourself with the functions ODEgeneRegulation() and logicalRule().\nBoth functions model an AND gate where nodeA and nodeB positively regulate nodeC. This could represent that A and B are transcription factors that form a protein complex, and that is via this complex that they can regulate the expression of C. While ODEgeneRegulation() encodes this regulation with an ordinary differential equation that requires several parameters, logicalRule() only needs the logical operator relating the input genes.\ndef ODEgeneRegulation(a,t,parameters): \n    prod=parameters['prod']\n    decay=parameters['decay']\n    Ksat=parameters['Ksat']\n    nodeA=parameters['nodeA']\n    nodeB=parameters['nodeB']\n    n=parameters['n']\n    outputC=a[0]\n    doutputC=prod*nodeA**n/(Ksat**n+nodeA**n)*nodeB**n/(Ksat**n+nodeB**n)-decay*outputC  \n    return(doutputC)\n\ndef logicalRule(nodeA,nodeB):\n    return(nodeA and nodeB)\nQ1 What is the minimum information you need to encode a regulatory interaction with either function? In what cases would you prefer to use an ODE or a logical rule for a model?\nLet’s run the model to simulate what happens if nodeA and nodeB are both active/expressed. Do this for the ODE and the Boolean logic code model using the following lines inside the main().\n# ODE model - see the parameters used in circuitsfunctions.py\n# ODErun has three arguments: model, geneA, geneB\nA=10\nB=10\nODErun(ODEgeneRegulation,A,B) \n\n# Boolean model\n# look at the terminal for the result:\nA=1\nB=1\nprint(\"the boolean operation of nodeA \",A,\" AND nodeB\",B,\" is:\", logicalRule(A,B))\nNow, let’s explore the output of each function using different values of nodeA and nodeB. We are going to use the code below to plot the output of the ODE and the Boolean model in a 2D heatmap.\n# First, Boolean network simulation - AND gate\nexplorationvalue=2 # a Boolean model assumes there is only 2 possible states: 0 or 1\nbool_output = np.zeros((explorationvalue, explorationvalue))\nfor nodeA in range(0, explorationvalue):\n    for nodeB in range(0, explorationvalue):\n        bool_output[nodeA, nodeB] = nodeA and nodeB #AND # CHANGE THIS\n\n# Now, ODE model simulation\nexplorationvalue = 11 # an ODE model allows us to explore more values than a boolean model\node_output = np.zeros((explorationvalue, explorationvalue))\nfor nodeA in range(0, explorationvalue):\n    for nodeB in range(0, explorationvalue):\n        parameters = {'prod': 0.01, 'decay': 0.001,'Ksat': 4, 'n': 2,'nodeA':nodeA,'nodeB':nodeB} # prod, decay, Ksat, n, and initial values for A and B\n        cells = odeint(ODEgeneRegulation, 0, np.arange(0, 1000.1 , 0.1), args=(parameters,)) #np.shape\n        ode_output[nodeA, nodeB] = cells[-1, 0]\n\n# use this code to see your ode and boolean results side by side\nODEBooleanPlot(ode_output, bool_output)\nQ2 What differences do you see in each case?\nNow let’s compare how ODE and Boolean logic represent different logical gates. You can use the same code in the previous box. Remember to modify the logical operator in the Boolean section, and to modify the doutputC equation in ODEgeneRegulation:\n\neither nodeA or nodeB can activate outputC (OR gate)\nthat nodeA represses outputC (NOT gate)\nthat both nodeA and nodeB repress outputC (NOT nodeA & NOT nodeB )\nthat nodeA represses outputC but nodeB activates it (NOT nodeA, yes nodeB)\nthat nodeA or nodeB can activate outputC, but not both at the same time (XOR gate)\nany other biological scenario yon can think of!\n\n\ntip: include an extra input node, and make a 3-node logical gate.\n\nQ3 Is there a logical gate that can be better represented with an ODE than with Boolean logic? Think of examples of biological regulatory interactions that can be described with each logical gate?",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Practical 4</span>"
    ]
  },
  {
    "objectID": "morpho_practical_1.html#part-ii-gene-regulatory-network",
    "href": "morpho_practical_1.html#part-ii-gene-regulatory-network",
    "title": "10  Practical 4",
    "section": "10.3 Part II – Gene regulatory network",
    "text": "10.3 Part II – Gene regulatory network\nNow let’s move to a network model made of many individual regulatory interactions. This model includes regulatory interactions experimentally determined in the cells of plant roots, here they encoded as logical rules. The model consists of 18 nodes representing transcription factors, hormones, peptides, and multitude regulatory interactions among them. Look at the rootNetwork() function in the circuitFunctions.py file. See how the activity of each node is determined by the state of its regulators using and combining the logical operators AND, OR and NOT. Find the model here: https://www.nature.com/articles/s41598-020-60251-8\nLet’s define a random initial condition for each of these 18 nodes, and the timesteps to solve the system using the logical functions. To find the state of the nodes in the network the next timestep, we need to give the state of our nodes to the rootNetwork() function, and then save the output of this function. We will save in matrix the initial condition, and how these 18 nodes change in the timesteps defined. At the end the function plotBooleanTimecourse() will show us the network changes in the simulated timesteps. * tip: 100 timesteps is enough to reach the attractors. For the initial condition you can also use that of one of the attractors reported in the paper and check what happens when you update them.\ntimesteps=20\nnodes=18\nmatrix = np.zeros((timesteps+1, nodes), dtype=int) \nmatrix[0,:] = np.random.randint(0, 2, size=nodes) #Random initial condition\nfor i in range(timesteps):\n    parameters= {'CK': matrix[i,0], 'ARR1': matrix[i,1], 'SHY2': matrix[i,2], 'AUXIAAR': matrix[i,3], 'ARFR': matrix[i,4], 'ARF10': matrix[i,5], 'ARF5': matrix[i,6], 'XAL1': matrix[i,7], 'PLT': matrix[i,8], 'AUX': matrix[i,9], 'SCR': matrix[i,10], 'SHR': matrix[i,11], 'MIR165': matrix[i,12], 'PHB': matrix[i,13], 'JKD': matrix[i,14], 'MGP': matrix[i,15], 'WOX5': matrix[i,16], 'CLE40': matrix[i,17]}\n    matrix[i+1, :] = rootNetwork(parameters)\n\nplotBooleanTimecourse(matrix,timesteps)\nInstead of a random initial condition try this one:\nmatrix[0,:]=[0,1,1,0,1,1,0,0,1,0,1,1,1,1,1,0,1,0]\nUse the asynchronous updating scheme by changing the function to rootNetworkAsynchronous() and see what happens to this initial condition.\nQ4 What happens now and why? What does an asyncrhonous update is doing?\nThis network has 18 nodes, and then 218 = 262,144 possible states. We can either solve each of these conditions, or instead explore just a subset of them. Using the previous code, add for loop to solve 100 random initial conditions, and then save the final activity configurations (attractors) in the attractors matrix. *tip: 100 initial conditons is a good number to start with. # The attractors matrix should have the shape (initial_conditions, nodes) so that you can plot the results using the function plotBooleanAttractors.\nICs=100\nattractors = np.zeros((ICs, len(parameters))) # new\n\n# your code\n\nplotBooleanAttractors(attractors) # it takes as argument your matrix of attractors\nYou probably found many different attractors. First, let’s use a multidimensional reduction technique to see if each of initial conditions form groups of similar cells.\nUMAPBoolean(attractors)\nQ5 Why do you see clearly defined groups and not a continuous distribution of attractors?\nNow let’s analyse the attractors you found. First, let’s group similar attractors:\nattractors_sorted = np.array(sorted(attractors.tolist()))\nplotBooleanAttractors(attractors_sorted) \nQ6 Do some attractors occur more frequently than others. Do they all have the same basin size of attraction? Why is this?\nQ6.1 Some nodes are active (1) in most attractors, others in half, and others in very few. In how many of them is the node SHR active? What does this suggest about their regulation?\nNow let’s remove the repeated rows (duplicate attractor states) to see unique attractors:\n_, unique_indices = np.unique(attractors, axis=0, return_index=True)\nattractors_unique = attractors[np.sort(unique_indices)]\nplotBooleanAttractors(attractors_unique) \nQ7 How many unique attractors did you find? Compare them with the ones reported in the paper. Are they all fixed points?",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Practical 4</span>"
    ]
  },
  {
    "objectID": "morpho_practical_1.html#part-iii-cell-differentiation-jumping-from-one-attractor-to-another",
    "href": "morpho_practical_1.html#part-iii-cell-differentiation-jumping-from-one-attractor-to-another",
    "title": "10  Practical 4",
    "section": "10.4 Part III – Cell differentiation – jumping from one attractor to another",
    "text": "10.4 Part III – Cell differentiation – jumping from one attractor to another\nDepending on what we want to answer a continuous or discrete model may be more appropriate for a model. To study the role of many genes in cell differentiation, a Boolean model might be better particularly if we lack details of the parameters underlying each reaction. If we want to study how cells jump from one state to another, a continuous model might be more appropriate.\nHere we will see how we can convert the Boolean model to a continuous one and use it to predict which regulators are able of causing a change in the state of the system (changes in cell fate!)\nCompare the code of the functions rootNetwork() and rootNetworkODE(). Notice how in rootNetworkODE() the logical rules are represented with min and max functions, and then used in a sigmoidal function to create a continuous ODE model. * AND operator is a min function, OR operator is a max function, and NOT operator is 1-x. Use the code below to run a random initial condition for the 18 nodes (IC) and see how the system behaves.\ntimerunning=10.1 \ntimes = np.arange(0, timerunning, 0.1)\n\nIC = np.random.randint(0, 2, size=18).tolist() #random initial condition\nparameters = {'decayrate': 1, 'h': 50} \ncells = odeint(rootNetworkODE, IC, times, args=(parameters,)) \n\nplotODEroot(cells,times)\nQ8 Do the attractors match those recovered with the Boolean network?\nNow let’s use the model to study cell differentiation. Let’s start in the following initial condition (IC vector), and find a change in a node that produce a jump to another attractor (end). For this you can simply flip the activity of a gene in the initial condition (from 0 -&gt;1 or 1-&gt;0) and see the final attractor matches the desired end state.\n# We start here: \nIC=[0,0,0,0,1,0,1,1,1,1,1,1,1,0,1,0,1,0]\n# We want to end here. \nend=[1,1,0,0,1,1,1,1,1,1,0,0,1,0,0,0,0,1]\n# node order\n# CK, ARR1, SHY2, AUXIAAR, ARFR, ARF10, ARF5, XAL1, PLT, AUX, SCR, SHR, MIR165, PHB, JKD, MGP, WOX5, CLE40\n\n# your code \n\nplotODErootTransition(cells,times) # use this function to plot your result\nQ9 What regulator causes the transition between these attractors? How many nodes change their activity between the initial and final state? what could be the biological meaning of this switch? how would you test this experimentally?\nQ10 Finally, use the model to predict the rest of the attractor transitions because of single node changes. Are all attractor transitions possible, or are there preferred differentiation routes?",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Practical 4</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html",
    "href": "morpho_practical_2.html",
    "title": "11  Practical 5",
    "section": "",
    "text": "TODO",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html#gene-regulatory-interactions",
    "href": "morpho_practical_2.html#gene-regulatory-interactions",
    "title": "11  Practical 5",
    "section": "11.1 Gene regulatory interactions",
    "text": "11.1 Gene regulatory interactions\nIn this practical you will get hands on experience on building models of gene regulatory interactions. Today you will:\n\nmake logical functions and ODE to describe gene regulation examples\nuse a Boolean network of a relatively large network to find the attractors\nuse an ODE model based on the boolean model to predict how to jump from one attractor to other (cell fate changes!)",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html#gene-regulation-examples",
    "href": "morpho_practical_2.html#gene-regulation-examples",
    "title": "11  Practical 5",
    "section": "11.2 Gene regulation Examples",
    "text": "11.2 Gene regulation Examples\nAdd an overview of genetic regulation and its importance in biological systems.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html#boolean-network-model",
    "href": "morpho_practical_2.html#boolean-network-model",
    "title": "11  Practical 5",
    "section": "11.3 Boolean network model",
    "text": "11.3 Boolean network model\nSummarize key concepts and terminology related to gene regulation.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html#boolean-network",
    "href": "morpho_practical_2.html#boolean-network",
    "title": "11  Practical 5",
    "section": "11.4 Boolean-network",
    "text": "11.4 Boolean-network\nDescribe mathematical and computational models used to study gene regulation over time.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html#umap",
    "href": "morpho_practical_2.html#umap",
    "title": "11  Practical 5",
    "section": "11.5 UMAP",
    "text": "11.5 UMAP\nProvide practical examples or case studies.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_practical_2.html#references",
    "href": "morpho_practical_2.html#references",
    "title": "11  Practical 5",
    "section": "11.6 References",
    "text": "11.6 References\nList relevant literature and resources.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Practical 5</span>"
    ]
  },
  {
    "objectID": "morpho_answers.html",
    "href": "morpho_answers.html",
    "title": "12  Answers exercises",
    "section": "",
    "text": "12.1 Answers practical 4 (gene regulation in time)\nQ1 To make an ODE model it is needed: the two nodes interacting interaction, direction and effect, and several parameters (4: prod, decay, Ksat, n). For Boolean you need the two nodes interacting interaction, direction and effect; no parameters needed.\nQ2 Quantitative differences in output (continuous can have values between 0 and 1, but also over 1).\nQ3 All logical gates can be modelled correctly with either approach. With Boolean models we look quantitative resolution, with ODE we can model many more values than 0 and 1. Biological examples that can be modelled with the logical gates: - AND gate can be that both genes form a protein complex that binds promoter. - OR is that either TF can bind promoter and activate transcription. - NOT is that a TF blocks the promoter so that activating TF cannot bind. - NOT A & NOT B is that both TFs are repressors of the same gene. - NOT A, yes B is that A is a repressor and B is an activator. - XOR gate can be a promoter where either A or B can bind, the complex AB cannot bind.\nQ4 The initial condition now converges to a fixed point attractor; the cyclic behaviour recovered with the synchronous updating scheme was an artifact of updating all the nodes at the same time.\nQ5 We see clearly defined groups because we are doing the UMAP with the cells in the final attractors, and not while they are in their trajectory towards the attractor.\nQ6 Yes, some attractors occur more often than others, and this is a consequence of the regulatory interactions integrated in the model. The number of initial conditions you found in each attractor is a reflection of the size of their basin of attraction. Indeed, the basins of attraction (all conditions that converge to an attractor) are shaped by the AND, OR, and NOT gates in each of the modelled nodes. Imagine cells are moving in a multidimensional landscape (as many dimensions as nodes in the model), such that the regulatory interactions define the “rolling” direction until eventually they land in different basins.\nQ6.1 This is defined by their logical rules, and how many regulators they have. For example, SHR logical rule is SHR = SHR. This splits the state space perfectly in two halves: one with SHR active and another with SHR inactive.\nQ7 This depends on how many initial conditions you test. The more initial conditions, the more likely you will find the maximum of 6 fixed point attractors this model can produce.\nQ8 Yes. The ODE model is built with the same regulatory interactions from the Boolean model. The difference is that this model allows us to describe quantitative differences in the activity of the nodes.\nQ9 SHR OFF (0) causes the transition between the specified activity configurations. We can interpret this change between attractors as a cell fate change, in which the decrease in SHR activity triggers changes in other nodes of the network resulting in the differentiation of the cells.\nQ10 Finally, use the model to predict the rest of the attractor transitions because of single node changes. Are all attractor transitions possible, or are there preferred differentiation routes? Not all attractor transitions are possible by single node changes. This is because the regulatory interactions in the model constrain how this perturbation is interpreted, and with it the differentiation trajectories.",
    "crumbs": [
      "II) Morphogenesis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Answers exercises</span>"
    ]
  },
  {
    "objectID": "differentiation_intro_text.html",
    "href": "differentiation_intro_text.html",
    "title": "13  Differentiation introduction",
    "section": "",
    "text": "TODO\n\nWrite a brief intro to the differentiation practicals",
    "crumbs": [
      "III) Cell differentiation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "differentiation_practical_1.html",
    "href": "differentiation_practical_1.html",
    "title": "14  Practical 6",
    "section": "",
    "text": "TODO\n\nCouldn’t find text (yet)?",
    "crumbs": [
      "III) Cell differentiation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Practical 6</span>"
    ]
  },
  {
    "objectID": "differentiation_practical_2.html",
    "href": "differentiation_practical_2.html",
    "title": "15  Practical 7",
    "section": "",
    "text": "TODO\n\nComplete the text on this page.",
    "crumbs": [
      "III) Cell differentiation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Practical 7</span>"
    ]
  },
  {
    "objectID": "evo_intro_text.html",
    "href": "evo_intro_text.html",
    "title": "16  Introduction to evolution",
    "section": "",
    "text": "16.1 Evolution: Life’s most clever algorithm\nEvolution is the process by which populations change over generations through variation, inheritance, and differential survival. This idea, famously championed by Darwin and Wallace, explains the diversity of life on Earth. It describes how species adapt to their environments, how new species arise, and how complex traits evolve. Today, the concept of evolution has expanded beyond biology, it’s recognised as a powerful algorithm that drives adaptation in systems ranging from bacteria (genes) to ideas (memes), from DNA (nucleotides) to computer code (bits).\nIn this part of the course, we’ll bring these ingredients to life by writing our own simulations and watching evolution unfold on the screen. And while our digital creatures aren’t made of flesh and blood, the evolutionary battles they fight, the strategies they discover, and the adaptations they evolve are as real, and often as surprising, as anything found in nature itself.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to evolution</span>"
    ]
  },
  {
    "objectID": "evo_intro_text.html#three-ingredients",
    "href": "evo_intro_text.html#three-ingredients",
    "title": "16  Introduction to evolution",
    "section": "16.2 Three ingredients",
    "text": "16.2 Three ingredients\nAs briefly mentioned above, we just need three ingredients to have evolution by means of natural selection:\n\nvariation (differences between individuals),\ninheritance (the passing on of traits),\nselection (some variants performing better than others).\n\nThe last ingredient is self-evident. Evolution by means of natural selection requires selection. It is especially the first two that are a little more tricky to really understand, as they are not always as obvious as they seem.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to evolution</span>"
    ]
  },
  {
    "objectID": "evo_intro_text.html#balancing-change-and-stability",
    "href": "evo_intro_text.html#balancing-change-and-stability",
    "title": "16  Introduction to evolution",
    "section": "16.3 Balancing change and stability",
    "text": "16.3 Balancing change and stability\nTo evolve, a system needs enough variation – if everyone is the same, there’s nothing for selection to act on. But this variation can’t just be noise; it needs to be passed on. That means inheritance can’t be perfect – there must be room for change, such as through mutations – but it also can’t be too sloppy. If traits aren’t reliably transmitted to the next generation, then even the best adaptations will vanish before they can take hold. Evolution lives in the sweet spot: not too rigid, not too chaotic, just enough memory and just enough change. To make this a little more tangible, let us make our very first simulation.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to evolution</span>"
    ]
  },
  {
    "objectID": "evo_intro_text.html#a-simple-evolutionary-algorithm",
    "href": "evo_intro_text.html#a-simple-evolutionary-algorithm",
    "title": "16  Introduction to evolution",
    "section": "16.4 A simple evolutionary algorithm",
    "text": "16.4 A simple evolutionary algorithm\nOne simple way to simulate evolution is with a Moran process, a classic model from population genetics. Imagine a population of 100 individuals, each with a single gene that determines its fitness. This gene can have all values from 0 to 1 (let’s call this value \\(\\phi\\)). At each time step, one individual is chosen to reproduce with a probability proportional to \\(\\phi\\), producing 1 offspring. This offspring inherits their parents gene (so the same \\(\\phi\\)), but with a probability \\(\\mu\\), the value changes by a small amount (a mutation). The population size will now be 101, which could be interesting if we want to study population growth. However, in a Moran process we keep it simple: one random individual is removed by the new offspring, so the population size is constant while still allowing fitter individuals to spread over time.\nHere’s a minimal Python example:\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(5)\n\nN = 100 # Population size \nfitnesses = np.full(N, 0.05)\nmu = 0.01\n# Updated parameters\nsteps = 50000\navg_fitness = []\n\n# Moran process with mutation (logging every 10 steps)\nfor step in range(steps):\n    probs = fitnesses / fitnesses.sum()\n    parent = np.random.choice(N, p=probs)\n    dead = np.random.choice(N)\n\n    # Copy with mutation\n    new_fit = fitnesses[parent]\n    if np.random.rand() &lt; mu:\n        new_fit = np.clip(new_fit + np.random.normal(0, 0.05), 0, 1)\n            \n    fitnesses[dead] = new_fit\n\n    # Save average fitness every 10 steps\n    if step % 10 == 0:\n        avg_fitness.append(fitnesses.mean())\n\n# Plotting\nplt.plot(np.arange(0, steps, 10), avg_fitness)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Average fitness\")\nplt.title(\"Evolution of Fitness in a Moran Process\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\nExercise 16.1 (Moran process simulation) \nStudy the Python code for the evolutionary algorithm given above. Answer the following questions:\n\nHow “well adapted” is the initial population?\nHow are mutations implemented in the code? Can you think of other ways?\nCan the parent be replaced by its own offspring? Why/why not?\nInvestigate which value of \\(\\mu\\) works best if you want to achieve maximum fitness in the shortest amount of steps.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to evolution</span>"
    ]
  },
  {
    "objectID": "evo_intro_text.html#what-this-part-of-the-course-is-about",
    "href": "evo_intro_text.html#what-this-part-of-the-course-is-about",
    "title": "16  Introduction to evolution",
    "section": "16.5 What this part of the course is about",
    "text": "16.5 What this part of the course is about\nThe above simulation is fun, but not really… biologically relevant. While some simplifications are necessary to make models feasible, we will investigate a few evolutionary models that are somewhat more interesting. We will discuss how to model spatial structure and local competition, how genotypes (where mutations happen) get translated into phenotypes (where selection happens), and how the environment can change over time and lead to niche construction and interactions.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to evolution</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html",
    "href": "evo_practical_1.html",
    "title": "17  Practical 1",
    "section": "",
    "text": "17.1 Sticking together\nIn this practical, you will practice building your own model of collective behaviour, based on the one you saw at the end of the lecture:\nThe example above is a implemented in Javascript, a programming language that is widely used for web development. It is easy to share with others, interactive, and surprisingly fast. But, it’s not the most “professional” programming language. Plus, at this stage of the course there is no point in learning yet another programming language, as you are here to learn about modelling biology. So we will stick to Python.\nFirst, let’s discuss how we can let individuals walk around in space.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#steering",
    "href": "evo_practical_1.html#steering",
    "title": "17  Practical 1",
    "section": "17.2 Steering",
    "text": "17.2 Steering\nWe can represent a moving individual in space as a point with a position and a velocity. The position is represented by two coordinates, \\(x\\) and \\(y\\), and the velocity is represented by two components, \\(v_x\\) and \\(v_y\\). All movement that this individual can do, will be a matter of repeatedly updating its position based on their velocity:\n\n\n\n  \n  \n  Vector Visualisation\n  \n\n\n  \n\n  \n    ← \n    → \n    ↑ \n    ↓ \n    ⟲ \n    ⟳ \n  \n\n  \n\n\n\n\n To model such a vector in python, we can simply define a base point with an x- and y-coordinate, and a velocity vector with an x- and y-component. The position of the individual can then be updated by adding the velocity to the position. Combining that with a function that draws an arrow in Python, we get the following code:\n\n\n\n\n\n\nCODE FOR “moving vector in Python”\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Enable interactive mode for matplotlib\nplt.ion()\n\n# Setup figure and axis for plotting the arrow\nfig, ax = plt.subplots(figsize=(8, 4))\nax.set_xlim(0, 600)  # x-axis limits\nax.set_ylim(0, 250)  # y-axis limits\nax.set_aspect('equal')  # Keep aspect ratio square\nax.set_facecolor('#f0f0f0')  # Background color\nax.set_title(\"A moving vector with an arrowhead\")  # Title\n\n# Initial position and velocity\nx, y = 250.0, 180.0      # Position coordinates\nvx, vy = 5.0, 10.5        # Velocity components\n\n\ndef draw_arrow(x, y, vx, vy):\n    \"\"\"\n    Draws an arrow at position (x, y) with velocity (vx, vy).\n    \"\"\"\n    ax.clear()\n    ax.set_xlim(0, 600)\n    ax.set_ylim(0, 250)\n    ax.set_aspect('equal')\n    ax.set_facecolor('#f0f0f0')\n    ax.set_title(\"A moving vector with an arrowhead\")\n\n    # Normalize velocity for drawing the arrow\n    \n    dx = vx*5\n    dy = vy*5\n\n    # Arrow shaft\n    end_x = x + dx\n    end_y = y + dy\n\n    # Arrowhead calculation\n    angle = np.arctan2(dy, dx)\n    angle_offset = np.pi / 7\n    hx1_x = end_x - np.cos(angle - angle_offset)\n    hx1_y = end_y - np.sin(angle - angle_offset)\n    hx2_x = end_x - np.cos(angle + angle_offset)\n    hx2_y = end_y - np.sin(angle + angle_offset)\n\n    # Draw shaft\n    ax.quiver(x, y, dx, dy, angles='xy', scale_units='xy', scale=1, color='#007acc', width=0.005)\n    # Draw base point\n    ax.plot(x, y, 'o', color='#333')\n\n    # Labels\n    ax.text(x+10, y+10, f\"x = {x:.2f}\")\n    ax.text(x+10, y-5, f\"y = {y:.2f}\")\n    ax.text(end_x + 10, end_y - 20, f\"vₓ = {vx:.2f}\")\n    ax.text(end_x + 10, end_y, f\"vᵧ = {vy:.2f}\")\n\n    plt.draw()\n    plt.pause(0.03)\n\n# Animation loop: update position by velocity\nfor i in range(500):\n    x += vx*0.1  # Update x position\n    y += vy*0.1  # Update y position\n\n    # Wrap around edges\n    x %= 600\n    y %= 250\n    \n    draw_arrow(x, y, vx, vy)\n\nplt.ioff()\n\n\n\n\nExercise 17.1 (Playing with steering arrows) \nCopy-paste the code above, study it for a few minutes, and run it.\n\nWhat can you do to make the arrow accelerate?\n\nTo rotate a vector, we can use the following trigonometrical equations, where \\(\\theta\\) is the angle of rotation:\n\\[\n\\begin{aligned}\nx_{new} = x \\cdot cos(\\theta) - y \\cdot sin(\\theta) \\newline\ny_{new} = x \\cdot sin(\\theta) + y \\cdot cos(\\theta)\n\\end{aligned}\n\\]\n\nUse the equation above to rotate the velocity vector in the code by a small angle every timestep. What happens?\nModelling 1 individual is not very exciting. Think about what the code above would look like if you had more than 1 individual. Discuss this with other students and/or Bram.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#moving-cells",
    "href": "evo_practical_1.html#moving-cells",
    "title": "17  Practical 1",
    "section": "17.3 Moving “cells”",
    "text": "17.3 Moving “cells”\nIn this practical, you will practice with modelling individuals in space by modifying a Python code based on the foraging cells shown at the beginning. To accommodate for many cells, we will define a new Cell class, embedded in a Simulation class.1\nFirst, read the code yourself (you can ignore the Visualisation class), and see if you can get it running on your own laptop.\n\n\n\n\n\n\nSTARTING CODE FOR “moving cells”\n\n\n\n\n\n###\n# PRACTICAL 1 | \"Every cell for themselves?\"\n# This is the starting code. Follow the instructions in the practical to complete the code. \n# If you get stuck, you can look at the final code in `foraging_for_resources_final.py`, or ask\n# Bram. \n#\n# The structure of this code is as follows:\n# 1. Imports and parameters\n# 2. Simulation class\n# 3. Cell class\n# 4. Visualisation class (you do not need to change this)\n#\n###\n\n# 1. IMPORTS AND PARAMETERS\n# Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.widgets import Slider\n\n# Parameters for simulation\nWORLD_SIZE = 200    # Width / height of the world (size of grid and possible coordinates for cells)\nMAX_VELOCITY = 0.3  # Maximum velocity magnitude\nMAX_FORCE = 0.3     # Maximum force magnitude\nRANDOM_MOVEMENT  = 0.01 # Random movement factor to add some noise to the cell's movement\n\n# Parameters for display\nDRAW_ARROW = True  # Draw the arrows showing the velocity direction of the cells\nINIT_CELLS = 20 # Initial number of cells in the simulation\nDISPLAY_INTERVAL = 1 # Frequency with which the plot is updated (e.g., every 10 timesteps can speed things up)\n\n# 1. MAIN LOOP (using functions and classes defined below)\ndef main():\n    \"\"\"Main function to set up and run the simulation.\"\"\"\n    # NOTE: The `Visualisation` class is responsible for managing the visualization \n    # of the simulation, including creating plots, updating them, and handling \n    # user interactions like the slider. As this has nothing to do with modeling\n    # per se, understanding this code is not necessary, but it can be fun to look\n    # at if you are interested. \n    \n    num_cells = INIT_CELLS\n    sim = Simulation(num_cells) \n\n    plt.ion()\n    vis = Visualisation(sim)\n\n    def update_cells(val):\n        sim.initialise_cells(int(vis.slider.val))\n        vis.redraw_plot(sim)\n        \n    # Connect the slider to the update function\n    vis.slider.on_changed(update_cells)\n\n    # Run simulation\n    for t in range(1, 10000):\n        \n        sim.simulate_step()\n        \n        if(t % DISPLAY_INTERVAL == 0):\n            # As long as only cells move, update only positions and timestamp\n            vis.update_plot(sim) \n            vis.ax.set_title(f\"Timestep: {t}\")\n            vis.fig.canvas.draw_idle()\n            plt.pause(10e-20)        \n        if(sim.redraw):\n            # When more has changes (e.g. number of cells or target position), redraw the plot\n            vis.redraw_plot(sim) \n            sim.redraw = False # Make sure it doesn't keep redrawing if not necessary\n        \n\n    # Keep the final plot open\n    plt.ioff()\n    # plt.show()\n\n\n\n# 2. SIMULATION CLASS\nclass Simulation:\n    \"\"\"Manages the grid, cells, target, and simulation logic.\"\"\"\n    def __init__(self, num_cells):\n        # Initialise a grid for the simulation\n        self.grid = np.zeros((WORLD_SIZE, WORLD_SIZE))  # Initialise an empty grid\n        self.fill_grid(self.grid, 0, 0, 0, 0)           # Fill grid with values (currently just 1s)\n        # Initialise a population of cells\n        self.cells = []\n        self.initialise_cells(num_cells)\n        # Place a 'target' in the middle\n        self.target_position = [WORLD_SIZE/2, WORLD_SIZE/2] \n        # A flag to only rebuild the plot when necessary (e.g. when the number of cells changes)\n        self.redraw = False\n\n    def simulate_step(self):\n        \"\"\"Simulate one timestep of the simulation.\"\"\"\n        for cell in self.cells:\n            # Actions taken by each cell. Most of them are still undefined, so you can implement them yourself.\n            self.move_towards_dot(cell)  \n            if self.check_target_reached(cell):\n                print(f\"Target reached!\")\n                self.reproduce_cell(cell)\n                self.redraw = True\n            \n            #self.avoid_collision(cell)\n            #self.stick_to_close(cell)\n            #self.find_peak(cell)\n\n            # Apply forces and update position\n            cell.apply_forces()\n            cell.update_position()\n\n            # Limit velocity to the maximum allowed\n            cell.vx = np.clip(cell.vx, -MAX_VELOCITY, MAX_VELOCITY)\n            cell.vy = np.clip(cell.vy, -MAX_VELOCITY, MAX_VELOCITY)\n\n    def initialise_cells(self, num_cells):\n        \"\"\"Initialise the cells with random positions and velocities.\"\"\"\n        self.cells = []\n        for _ in range(num_cells):\n            x = np.random.uniform(0, WORLD_SIZE)\n            y = np.random.uniform(0, WORLD_SIZE)\n            vx = np.random.uniform(-1, 1)\n            vy = np.random.uniform(-1, 1)\n            self.cells.append(Cell(x, y, vx, vy))\n\n    def fill_grid(self, grid, mean_x, mean_y, std_dev, noise=0):\n        \"\"\"\n        Write a function that takes the 2D grid and fills it with values representing \n        a Gaussian (normal) distribution centered at (mean_x, mean_y). See\n        if you can use the 'noise' argument to randomise the gaussian distribution a bit.\n        \n        Hint: e^{-x^2} yields a bell curve centered around 0. \n        \n        \"\"\"\n        for i in range(WORLD_SIZE):\n            for j in range(WORLD_SIZE):\n                x = i / (WORLD_SIZE - 1)\n                y = j / (WORLD_SIZE - 1)\n                grid[i, j] = 1 # This is 1 in the example, but should be a Gaussian distribution\n\n        # Normalize the grid to keep the total resource concentration the same\n        self.grid = grid\n    \n    def find_peak(self, cell):\n        \"\"\"Make the cell move towards the peak of the resource gradient with a random walk.\"\"\"\n        # Convert cell position to grid indices, as well as the previous position\n        grid_x = int(cell.x) % WORLD_SIZE\n        grid_y = int(cell.y) % WORLD_SIZE\n        next_x = (int(cell.x + 30*cell.vx) + WORLD_SIZE) % WORLD_SIZE \n        next_y = (int(cell.y + 30*cell.vy) + WORLD_SIZE) % WORLD_SIZE \n         \n    \n    def avoid_collision(self, cell):\n        \"\"\"Implement a simple collision avoidance mechanism. You can do so by\n        checking if this individual overlaps with another individual, and if so,\n        applying a repulsion force to the individual apposing the overlapping\n        direction.\"\"\"\n        for other_cell in self.cells:\n            if other_cell is not cell:\n                # Calculate the distance between the two cells\n                dx = cell.x - other_cell.x\n                dy = cell.y - other_cell.y\n                distance = np.sqrt(dx**2 + dy**2)\n                \n                    \n    def stick_to_close(self, cell):\n        \"\"\"Implement an attraction to cells that are nearby (but not overlapping)\"\"\"\n        for other_cell in self.cells:\n            if other_cell is not cell:\n                # Calculate the distance between the two cells\n                dx = cell.x - other_cell.x\n                dy = cell.y - other_cell.y\n                distance = np.sqrt(dx**2 + dy**2)\n\n    \n    def move_towards_dot(self, cell):\n        \"\"\"\n        Write your own function that applies forces in the direction of the dot.\n        Try to think of a way to apply the same force to every cell irrespective\n        of the distance to the dot, such that the cells move towards the dot at \n        the same speed. \n        \n        To get you started, the function already calculates dx and dy, which are\n        the distances to the target position in the x and y direction, respectively.\n        \"\"\"\n        # Calculate dx and dy\n        dx = self.target_position[0] - cell.x\n        dy = self.target_position[1] - cell.y\n        \n    \n    def check_target_reached(self, cell):\n        \"\"\"\n        Write your own function that checks if this cell has reached the target position.\n        You can do this by calculating the distance between the cell and the target.\n        If the distance is smaller than a certain threshold (e.g., 3 units), return True.\n        Otherwise, return False.\n        \"\"\"\n        \n        return(False)  # Dummy 'return' value. \n    \n    def reproduce_cell(self, cell):\n        \"\"\"\n        Write your own function that reproduces this cell. Think\n        about what it should inherit, and what it should *not* inherit. \n        \n        To keep the number of cell constant, you can first throw away a random cell.\n        \"\"\"\n        # Reproduce: Create a new cell with the same properties as the current cell\n        return(False) # Dummy 'return' value.\n\n        \n        \n# 3. CELL CLASS\nclass Cell:\n    \"\"\"Represents an individual cell in the simulation.\"\"\"\n    def __init__(self, x, y, vx, vy):\n        self.x = x\n        self.y = y\n        self.vx = vx\n        self.vy = vy\n        self.ax = 0\n        self.ay = 0\n        self.stickiness = 0.01 # Initial stickiness, can be adjusted later\n        \n    def update_position(self):\n        \"\"\"Update the cell's position based on its velocity.\"\"\"\n        self.x = (self.x + self.vx ) % WORLD_SIZE  # Wrap around the world\n        self.y = (self.y + self.vy ) % WORLD_SIZE  # Wrap around the world\n\n    def apply_forces(self):\n        \"\"\"Apply a force to the cell, updating its velocity.\"\"\"\n        self.ax = np.clip(self.ax, -MAX_FORCE, MAX_FORCE)\n        self.ay = np.clip(self.ay, -MAX_FORCE, MAX_FORCE)\n        self.vx += self.ax + RANDOM_MOVEMENT * np.random.uniform(-1, 1)\n        self.vy += self.ay + RANDOM_MOVEMENT * np.random.uniform(-1, 1)\n        # Apply drag to slow down the cell naturally\n        self.ax = 0\n        self.ay = 0\n        \n\n\n# Visualisation class for showing the individuals and the grid. For the practical, you do not need to change this. \nclass Visualisation:    \n    def __init__(self, sim):\n        fig, ax = plt.subplots(figsize=(6, 6))\n        self.cell_x = [cell.x for cell in sim.cells]\n        self.cell_y = [cell.y for cell in sim.cells]\n        self.cell_vx = np.array([cell.vx for cell in sim.cells])\n        self.cell_vy = np.array([cell.vy for cell in sim.cells])\n        self.cell_stickiness = np.array([cell.stickiness for cell in sim.cells])\n        # Colour cells by stickiness using inferno colormap\n        self.cell_scatter = ax.scatter(self.cell_x, self.cell_y, c=self.cell_stickiness, cmap='inferno', s=50, edgecolor='white', vmin=0, vmax=1)\n        if(DRAW_ARROW): self.cell_quiver = ax.quiver(self.cell_x, self.cell_y, self.cell_vx * 0.5, self.cell_vy * 0.5, angles='xy', scale_units='xy', scale=0.02, color='white')\n        plt.subplots_adjust(bottom=0.2)\n\n        ax.set_xlim(0, WORLD_SIZE)\n        ax.set_ylim(0, WORLD_SIZE)\n        ax.set_aspect('equal', adjustable='box')\n        ax.set_title(f\"Timestep: 0\")\n        ax.set_xlabel(\"X\")\n        ax.set_ylabel(\"Y\")\n\n        target_point=ax.scatter(sim.target_position[0], sim.target_position[1], c='purple', s=100, edgecolor='red')\n        grid_im=ax.imshow(sim.grid.T, extent=(0, WORLD_SIZE, 0, WORLD_SIZE), origin='lower', cmap='viridis', alpha=1.0)\n\n        self.fig = fig\n        self.ax = ax\n        self.target_point = target_point\n        self.grid_im = grid_im\n\n        # Add a slider for selecting the number of cells\n        ax_slider = plt.axes([0.2, 0.05, 0.6, 0.03])\n        self.slider = Slider(ax_slider, 'Cells', 1, 1000, valinit=len(sim.cells), valstep=1)\n\n    def update_cell_positions(self, sim):\n        \"\"\"Update the positions of the cells in the visualisation.\"\"\"\n        self.cell_x = [cell.x for cell in sim.cells]\n        self.cell_y = [cell.y for cell in sim.cells]\n        self.cell_vx = np.array([cell.vx for cell in sim.cells])\n        self.cell_vy = np.array([cell.vy for cell in sim.cells])\n        self.cell_stickiness = np.array([cell.stickiness for cell in sim.cells])\n    \n    def update_plot(self, sim):\n        self.update_cell_positions(sim)\n        self.cell_scatter.set_offsets(np.c_[self.cell_x,self.cell_y])\n        self.cell_scatter.set_array(self.cell_stickiness)\n        if(DRAW_ARROW): \n            self.cell_quiver.set_offsets(np.c_[self.cell_x, self.cell_y])\n            self.cell_quiver.set_UVC(self.cell_vx * 0.5, self.cell_vy * 0.5)        \n\n    def redraw_plot(self, sim):\n        self.update_cell_positions(sim)\n        cell_scatter_new = self.ax.scatter(self.cell_x, self.cell_y, c=self.cell_stickiness, cmap='inferno', s=50, edgecolor='white', vmin=0, vmax=1)\n        if(DRAW_ARROW): \n            cell_quiver_new = self.ax.quiver(self.cell_x, self.cell_y, self.cell_vx * 0.15, self.cell_vy * 0.15, angles='xy', scale_units='xy', scale=0.02, color='white')\n            self.cell_quiver.remove()\n            self.cell_quiver = cell_quiver_new\n        self.cell_scatter.remove()\n        self.fig.canvas.draw_idle()\n        self.cell_scatter = cell_scatter_new\n        self.grid_im.remove()\n        self.grid_im = self.ax.imshow(sim.grid.T, extent=(0, WORLD_SIZE, 0, WORLD_SIZE), origin='lower', cmap='viridis', alpha=1.0)\n        self.target_point.remove()\n        self.target_point=self.ax.scatter(sim.target_position[0], sim.target_position[1], c='purple', s=100, edgecolor='red')\n        plt.pause(10e-20)\n            \n            \n# 4. Execute the main loop\nif __name__ == \"__main__\":\n    # with cProfile.Profile() as pr:\n        main()\n        # pr.print_stats()\n\n\n\n\n\nMake sure you inspect the code. What features does the Simulation class have? What features does a Cell have?\nAs you can see if you inspected the code properly, many functions are left empty (or at least do not do anything yet). You will start filling these with your own code.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#sec-movingtarget",
    "href": "evo_practical_1.html#sec-movingtarget",
    "title": "17  Practical 1",
    "section": "17.4 Moving the target",
    "text": "17.4 Moving the target\nIf you run the code, you will see a purple dot (with a red outline). This may represent a “target”. It could represent a resource patch for bacteria, but it could also be a piece of fruit for a monkey (at this point, the model is still very abstract, so both could be true). Let’s make the target change position around after an individual touches it.\nTo help you on your way, first answer the following questions for yourself:\n\nHow can you calculate the distance between an individual and the orange dot?\nWhen is an individual close enough to the orange dot?\nHow can we assign a random position to the dot?\n\nFirst try it yourself. If you get stuck, ask Bram for help.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#sec-reproduction",
    "href": "evo_practical_1.html#sec-reproduction",
    "title": "17  Practical 1",
    "section": "17.5 Reproduction",
    "text": "17.5 Reproduction\nLet’s reward the individual that found the target. To do this, we can call the ‘Cell’ constructor to make a new cell, and add it to the list of cells:\nnew_cell = Cell(new_x, new_y, new_vx, new_vy, new_speed)\nself.cells.append(new_cell)\nConsider which properties of the parent cell get inherited to the child:\n\nShould the exact position be inherited to offspring? (yes/no)\nShould the offspring be placed nearby its parent? (yes/no)\nDoes the velocity get inherited?\n\nNote that depending on the scenario, the above questions may change. When a planktonic algea reproduces the daughter cells may inherit the velocity of the mother cell, but if a monkey gives birth, it does not make a lot of sense to talk about the ‘velocity’ of the mother. If we consider plants, we should not even consider velocity of the individuals at any stage of their life.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#sec-collision",
    "href": "evo_practical_1.html#sec-collision",
    "title": "17  Practical 1",
    "section": "17.6 Collision detection",
    "text": "17.6 Collision detection\nAs the cells move towards the dot, you may notice that cells start overlapping quite a bit. Let’s implement a simple form of collision detection, where overlap is resolved by pushing cells away from each other. Answer the following questions to get on your way:\n\nHow can you calculate the distance between two cells?\nWhen are two points overlapping?\nWhat can we do when two points overlap?\n\nNow that we have implemented both target-finding, reproduction, and collision, we can study these individual mechanisms by commenting one or the other out. This is an important process in understanding a model. Try it for yourself!",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#sec-resourcepeak",
    "href": "evo_practical_1.html#sec-resourcepeak",
    "title": "17  Practical 1",
    "section": "17.7 Implementing a resource peak",
    "text": "17.7 Implementing a resource peak\nAs you may have noticed when reading the code, it also includes a grid. However, you don’t see this grid yet, as the function fill_grid currently sets every point to 1.\nWe can loop over the grid coordinates by using a double for-loop:\nfor i in range(WORLD_SIZE):\n  for j in range(WORLD_SIZE):\n    grid[i,j] = 1\nThe above function loops over all the grid points, and set the value of each grid point to 1. Let’s use the function np.exp to calculate a Gaussian that we will place in the center of the grid. The fill_grid already takes as arguments the grid, a relative x-coordinate (0-1), a relative y-coordinate (0-1), and a standard deviation (0-1).\nGet started by answering the following questions:\n\nThe function \\(e^{-x^2}\\) gives a bell-curve centered around zero. How can you make it centered around a different value?\nCombined with the numpy function np.exp, how can we use the equation in question a to create a Gaussian that is at the center of the grid?",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#sec-runandtumble",
    "href": "evo_practical_1.html#sec-runandtumble",
    "title": "17  Practical 1",
    "section": "17.8 Run and tumble",
    "text": "17.8 Run and tumble\n\n\n\n“Test”\n\n\nBacterial cells are so small, that they cannot detect a gradient directly (in other words, they don’t know in which direction resources are higher!). Instead, bacteria often use a “run and tumble” strategy. When they are currently not detecting an increase in the concentration (over time), they tumble. If they do detect an increase, they keep moving in the same direction. This is a very simple strategy, but it can be very effective mechanism for chemotaxis.\nIn our earlier code of a single, moving vector, we rotated the arrow by changing the ‘angle’ variable. However, these cells do not have an angle parameters, but only a velocity vector with components \\(v_x\\) and \\(v_y\\). If we want to rotate the velocity vector, we can use the following equation (rooted in basic trigonometry):\n\\[\nv_x' = v_x \\cdot cos(\\theta) - v_y \\cdot sin(\\theta) \\\\\nv_y' = v_x \\cdot sin(\\theta) + v_y \\cdot cos(\\theta)\n\\]\nWhere \\(\\theta\\) is the angle we want the vector to rotate (in radians, not degrees!), and \\(v_x\\) and \\(v_y\\) are the components of the vector. With this in mind, let’s try and model chemotaxis. Do it in the following way:\n\nDetermine the concentration of the position of the cell, AND the predicted position of the cell after a small timestep (hint: use \\(v_x\\) and \\(v_y\\) to predict the future position! ask Bram if you get stuck)\nMake sure the future position is not outside of the grid! (hint: use Google, ChatGPT, or Copilot and figure out how the “modulo” operator works)\nIf the future position has a higher concentration than the current position, keep moving in more or less the same direction, with a very small change.\nIf the future position is a lower concentration, rotate the velocity vector a lot.\n\nStudy if your individuals can find the resource peak. Notice that depending on your implementation, cells may or may not work. Make sure to carefully investigate why it does or does not work.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#sec-sticking",
    "href": "evo_practical_1.html#sec-sticking",
    "title": "17  Practical 1",
    "section": "17.9 Sticking together",
    "text": "17.9 Sticking together\nCells sticking together can be implemented in multiple ways. Cells could be connected by a Newtonian spring, or we could simple make sure that cells that are close to each other are attracted to one another. In this case, we will use the latter method. Note that this is not very different from collision avoidance, but it is the other way around. In fact, we now have two opposing forces: cells are attracted to one another but do not want to overlap. This can be a bit finicky to get right, so feel free to explore. Ask for help if you get stuck.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#cells",
    "href": "evo_practical_1.html#cells",
    "title": "17  Practical 1",
    "section": "17.10 500 cells?",
    "text": "17.10 500 cells?\nTry to run the model with 500 cells. Also go back to the starting code again (without all the additions), and run this code with 500 cells too.\n\nWhat happens? Can you explain this?\n\nThis is far as this introduction to IBMs in python goes. Simple IBMs can be efficiently implemented in basic Python, but for more complex models, it is better to i) use numpy operations to speed up your Python code, or ii) use a faster programming language like C, Rust, or Javascript. For the last part of this pratical, we will study the Javascript version of this model. But before that, here is the final code that I ended up with:",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#final-python-code-for-interested-students",
    "href": "evo_practical_1.html#final-python-code-for-interested-students",
    "title": "17  Practical 1",
    "section": "17.11 Final Python code (for interested students)",
    "text": "17.11 Final Python code (for interested students)\nThis combination of individuals moving in continuous space, combined with a grid (e.g. with resources, or other environmental states) is a very useful way to make a spatially structured model.\n\n\n\n\n\n\nFinal code\n\n\n\n\n\n\n###\n# PRACTICAL 1 | \"Every cell for themselves?\"\n# Things in this model that you have tried to implement yourself:\n# 1. Implement collision avoidance\n# 2. Implement reproduction\n# 3. Implement a Gaussian grid\n# 4. Implement \"run and tumble\"\n# 5. Add noise to Gaussian, what happens?\n# 5. Modify collision into STICKING (a little finicky)\n# 6. Try it out with 500 cells... \n###\n\n###\n# PRACTICAL 1 | PLENARY DISCUSSION\n# What else was discussed in the plenary?\n# 1. Why are grids so popular in modelling?\n# 2. Tessellation of space\n# 3. Automatic tessellation of space: quad tree\n# 4. In the full model (javascript/Cacatoo), a quad tree is present, impacting performance\n###\n\n# 1. IMPORTS AND PARAMETERS\n# Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.widgets import Slider\n\n# Parameters for simulation\nWORLD_SIZE = 200  # Width / height of the world (size of grid and possible coordinates for cells)\nMAX_VELOCITY = 0.3  # Maximum velocity magnitude\nMAX_FORCE = 0.3  # Maximum force magnitude\nDRAG_COEFFICIENT = 0.01  # Friction to slow down the cell naturally\nRANDOM_MOVEMENT  = 0.01 # Random movement factor to add some noise to the cell's movement\nCELL_STICKINESS_LOW = 0.0 # Minimal stickiness of cells in population\nCELL_STICKINESS_HIGH = 0.10 # Maximal stickiness of cells in population\n# Parameters for display\nDRAW_ARROW = False  # Draw the arrows showing the velocity direction of the cells\nNOISE = 2 # Noise factor for the Gaussian grid (noise amount is raised to the power of this value)\nINIT_CELLS = 64 # Initial number of cells in the simulation\nSEASON_DURATION = 1000 # Duration of a season, after which the Gaussian grid is regenerated\nDISPLAY_INTERVAL = 5\n\n# 1. MAIN LOOP (using functions and classes defined below)\ndef main():\n    \"\"\"Main function to set up and run the simulation.\"\"\"\n    # Initialise simulation and its # The `visualis` variable in the code snippet provided is actually\n    # a misspelling of the correct variable name `vis`, which stands\n    # for the `Visualisation` class instance. The `Visualisation`\n    # class is responsible for managing the visualization of the\n    # simulation, including creating plots, updating them, and\n    # handling user interactions like the slider.\n    \n    num_cells = INIT_CELLS\n    sim = Simulation(num_cells) \n\n    plt.ion()\n    vis = Visualisation(sim)\n\n\n    def update_cells(val):\n        sim.initialise_cells(int(vis.slider.val))\n        vis.redraw_plot(sim)\n        \n    # Connect the slider to the update function\n    vis.slider.on_changed(update_cells)\n\n    # Run simulation\n    for t in range(1, 10000):\n        sim.simulate_step()\n        if(t % DISPLAY_INTERVAL == 0):\n            vis.update_plot(sim)\n            vis.ax.set_title(f\"Timestep: {t}\")\n            vis.fig.canvas.draw_idle()\n            plt.pause(10e-20)\n        if(t % SEASON_DURATION==0):\n            sim.fill_grid(sim.grid, 0.2+np.random.uniform(0,0.6), 0.2+np.random.uniform(0,0.6), 0.1, NOISE)\n            vis.redraw_plot(sim)# Create Gaussian grid\n        # Update title and redraw the plot\n\n    # Keep the final plot open\n    plt.ioff()\n    # plt.show()\n\n\n\n# 2. SIMULATION CLASS\nclass Simulation:\n    \"\"\"Manages the grid, cells, target, and simulation logic.\"\"\"\n    def __init__(self, num_cells):\n        self.grid = np.zeros((WORLD_SIZE, WORLD_SIZE))  # Initialise an empty grid\n        self.cells = []\n        self.target_position = [WORLD_SIZE/3, WORLD_SIZE/3]  # Initial target position at the center\n        self.target_position = [-1,-1]\n        self.fill_grid(self.grid, 0.5, 0.5, 0.1, NOISE)  # Create Gaussian grid\n        self.initialise_cells(num_cells)\n\n    def simulate_step(self):\n        \"\"\"Simulate one timestep of the simulation.\"\"\"\n        for cell in self.cells:\n            # Actions taken by each cell. Most of them are still undefined, so you can implement them yourself.\n            #self.move_towards_dot(cell)  \n            #if self.check_target_reached(cell):\n            #    print(f\"Target reached! New target position: {self.target_position}\")\n            #    self.reproduce_cell(cell) \n            \n            self.avoid_collision(cell)\n            self.stick_to_close(cell)\n            self.find_peak(cell)\n            \n            # Apply drag force to acceleration\n            cell.ax += -DRAG_COEFFICIENT * cell.vx\n            cell.ay += -DRAG_COEFFICIENT * cell.vy\n\n            # Apply forces and update position\n            \n            cell.apply_forces()\n            cell.update_position()\n\n            # Limit velocity to the maximum allowed\n            cell.vx = np.clip(cell.vx, -MAX_VELOCITY, MAX_VELOCITY)\n            cell.vy = np.clip(cell.vy, -MAX_VELOCITY, MAX_VELOCITY)\n\n    def initialise_cells(self, num_cells):\n        \"\"\"Initialise the cells with random positions and velocities.\"\"\"\n        self.cells = []\n        for _ in range(num_cells):\n            x = np.random.uniform(0, WORLD_SIZE)\n            y = np.random.uniform(0, WORLD_SIZE)\n            vx = np.random.uniform(-1, 1)\n            vy = np.random.uniform(-1, 1)\n            self.cells.append(Cell(x, y, vx, vy))\n\n    def fill_grid(self, grid, mean_x, mean_y, std_dev, noise=0):\n        \"\"\"Creates a Gaussian distribution with noise on the grid.\"\"\"\n        for i in range(WORLD_SIZE):\n            for j in range(WORLD_SIZE):\n                x = i / (WORLD_SIZE - 1)\n                y = j / (WORLD_SIZE - 1)\n                distance_squared = (x - mean_x)**2 + (y - mean_y)**2\n                grid[i, j] = np.exp(-distance_squared / (2 * std_dev**2)) * np.random.uniform(0.0, 1.0)**noise\n\n        # Normalize the grid to keep the total resource concentration the same\n        grid /= np.sum(grid)\n        self.grid = grid\n    \n    def find_peak(self, cell):\n        \"\"\"Make the cell move towards the peak of the resource gradient with a random walk.\"\"\"\n        # Convert cell position to grid indices, as well as the previous position\n        grid_x = int(cell.x) % WORLD_SIZE\n        grid_y = int(cell.y) % WORLD_SIZE\n        next_x = (int(cell.x + 10*cell.vx) + WORLD_SIZE) % WORLD_SIZE \n        next_y = (int(cell.y + 10*cell.vy) + WORLD_SIZE) % WORLD_SIZE \n        # Get the resource value at the cell's position, as well as the previous position\n        resource_value = self.grid[grid_x, grid_y]\n        resource_next = self.grid[next_x, next_y]\n        \n        # Check if the cell is moving in the right direction\n        if resource_next &gt; resource_value:\n            # Moving in the right direction: small random adjustment\n            angle = np.random.uniform(-0.1, 0.1)  # Small angle change\n        else:\n            # Moving in the wrong direction: large random adjustment\n            angle = np.random.uniform(-np.pi*1.0, np.pi*1.0)  # Large angle change\n        \n        # Rotate the velocity vector by the random angle according to trigonometric rotation formulas\n        new_vx = cell.vx * np.cos(angle) - cell.vy * np.sin(angle)\n        new_vy = cell.vx * np.sin(angle) + cell.vy * np.cos(angle)\n\n        # Update the acceleration with the new velocity vector, such that the cell moves towards the peak\n        cell.vx = new_vx\n        cell.vy = new_vy\n        cell.ax += cell.vx\n        cell.ay += cell.vy\n         \n    \n    def avoid_collision(self, cell):\n        \"\"\"Avoidance forces to prevent cells from colliding.\"\"\"\n        for other_cell in self.cells:\n            if other_cell is not cell:\n                # Calculate the distance between the two cells\n                dx = cell.x - other_cell.x\n                dy = cell.y - other_cell.y\n                distance = np.sqrt(dx**2 + dy**2)\n\n                # If the cells are too close, apply a repulsion force\n                if distance &lt; 5.0 and distance &gt; 0:  # Threshold for \"too close\"\n                    # Calculate the repulsion force proportional to the inverse of the distance\n                    force_magnitude = (5.0 - distance) / distance\n                    cell.ax += force_magnitude * dx  * 100\n                    cell.ay += force_magnitude * dy * 100\n                    \n    def stick_to_close(self, cell):\n        \"\"\"Stick to closeby cells.\"\"\"\n        for other_cell in self.cells:\n            if other_cell is not cell:\n                # Calculate the distance between the two cells\n                dx = cell.x - other_cell.x\n                dy = cell.y - other_cell.y\n                distance = np.sqrt(dx**2 + dy**2)\n\n                # If the cells are too close, apply a repulsion force\n                if distance &lt; 12 and distance &gt; 5:  # Threshold for \"close\"\n                    # Calculate the repulsion force proportional to the inverse of the distance\n                    cell.ax -= cell.stickiness * dx *10\n                    cell.ay -= cell.stickiness * dy *10\n    \n    def move_towards_dot(self, cell):\n        \"\"\"Apply forces in the direction of the dot.\"\"\"\n        # Calculate dx and dy\n        dx = self.target_position[0] - cell.x\n        dy = self.target_position[1] - cell.y\n        # Calculate the distance to the target (pythagorean theorem)\n        distance = np.sqrt(dx**2 + dy**2)\n        \n        # Normalize dx and dy \n        dx /= distance\n        dy /= distance\n        # Apply a small force towards the target\n        cell.ax += dx * 0.01\n        cell.ay += dy * 0.01\n    \n    def check_target_reached(self, cell):\n        distance_to_target = np.sqrt((cell.x - self.target_position[0])**2 +\n                                         (cell.y - self.target_position[1])**2)\n        if distance_to_target &lt; 3:\n            # Set a new target position\n            self.target_position = [np.random.uniform(0, WORLD_SIZE), np.random.uniform(0, WORLD_SIZE)]\n            return(True)\n        return(False)\n    \n    def reproduce_cell(self, cell):\n        # Reproduce: Create a new cell with the same properties as the current cell\n        angle = np.random.uniform(0, 2 * np.pi)\n        radius = np.random.uniform(0.05, 1.5)\n        new_x = cell.x + radius * np.cos(angle)\n        new_y = cell.y + radius * np.sin(angle)\n        new_cell = Cell(new_x, new_y, cell.vx, cell.vy)\n        random_cell = np.random.choice(self.cells)   \n        self.cells.remove(random_cell)\n        self.cells.append(new_cell)\n\n\n        \n        \n        \n# 3. CELL CLASS\nclass Cell:\n    \"\"\"Represents an individual cell in the simulation.\"\"\"\n    def __init__(self, x, y, vx, vy):\n        self.x = x\n        self.y = y\n        self.vx = vx\n        self.vy = vy\n        self.ax = 0\n        self.ay = 0\n        if(np.random.uniform(0,1) &lt; 0.5): \n            self.stickiness = CELL_STICKINESS_LOW\n        else:\n            self.stickiness = CELL_STICKINESS_HIGH\n        \n    def update_position(self):\n        \"\"\"Update the cell's position based on its velocity.\"\"\"\n        self.x = (self.x + self.vx ) % WORLD_SIZE  # Wrap around the world\n        self.y = (self.y + self.vy ) % WORLD_SIZE  # Wrap around the world\n\n    def apply_forces(self):\n        \"\"\"Apply a force to the cell, updating its velocity.\"\"\"\n        self.ax = np.clip(self.ax, -MAX_FORCE, MAX_FORCE)\n        self.ay = np.clip(self.ay, -MAX_FORCE, MAX_FORCE)\n        self.vx += self.ax + RANDOM_MOVEMENT * np.random.uniform(-1, 1)\n        self.vy += self.ay + RANDOM_MOVEMENT * np.random.uniform(-1, 1)\n        self.ax = 0\n        self.ay = 0\n        \n\n\n# Visualisation class for showing the individuals and the grid. For the practical, you do not need to change this. \nclass Visualisation:    \n    def __init__(self, sim):\n        fig, ax = plt.subplots(figsize=(6, 6))\n        self.cell_x = [cell.x for cell in sim.cells]\n        self.cell_y = [cell.y for cell in sim.cells]\n        self.cell_vx = np.array([cell.vx for cell in sim.cells])\n        self.cell_vy = np.array([cell.vy for cell in sim.cells])\n        self.cell_stickiness = np.array([cell.stickiness for cell in sim.cells])\n        # Colour cells by stickiness using inferno colormap\n        self.cell_scatter = ax.scatter(self.cell_x, self.cell_y, c=self.cell_stickiness, cmap='inferno', s=50, edgecolor='white', vmin=0, vmax=CELL_STICKINESS_HIGH*1.2)\n        if(DRAW_ARROW): self.cell_quiver = ax.quiver(self.cell_x, self.cell_y, self.cell_vx * 0.15, self.cell_vy * 0.15, angles='xy', scale_units='xy', scale=0.02, color='darkblue')\n        plt.subplots_adjust(bottom=0.2)\n\n        ax.set_xlim(0, WORLD_SIZE)\n        ax.set_ylim(0, WORLD_SIZE)\n        ax.set_aspect('equal', adjustable='box')\n        ax.set_title(f\"Timestep: 0\")\n        ax.set_xlabel(\"X\")\n        ax.set_ylabel(\"Y\")\n\n        target_point=ax.scatter(sim.target_position[0], sim.target_position[1], c='orange', s=50, edgecolor='white')\n        grid_im=ax.imshow(sim.grid.T, extent=(0, WORLD_SIZE, 0, WORLD_SIZE), origin='lower', cmap='viridis', alpha=1.0)\n\n        self.fig = fig\n        self.ax = ax\n        self.target_point = target_point\n        self.grid_im = grid_im\n        # Add a slider for selecting the number of cells\n        ax_slider = plt.axes([0.2, 0.05, 0.6, 0.03])\n        self.slider = Slider(ax_slider, 'Cells', 1, 1000, valinit=len(sim.cells), valstep=1)\n\n    def update_cell_positions(self, sim):\n        \"\"\"Update the positions of the cells in the visualisation.\"\"\"\n        self.cell_x = [cell.x for cell in sim.cells]\n        self.cell_y = [cell.y for cell in sim.cells]\n        self.cell_vx = np.array([cell.vx for cell in sim.cells])\n        self.cell_vy = np.array([cell.vy for cell in sim.cells])\n        self.cell_stickiness = np.array([cell.stickiness for cell in sim.cells])\n    \n    def update_plot(self, sim):\n        self.update_cell_positions(sim)\n        self.cell_scatter.set_offsets(np.c_[self.cell_x,self.cell_y])\n        self.cell_scatter.set_array(self.cell_stickiness)\n        if(DRAW_ARROW): \n            self.cell_quiver.set_offsets(np.c_[self.cell_x, self.cell_y])\n            self.cell_quiver.set_UVC(self.cell_vx * 0.15, self.cell_vy * 0.15)        \n\n    def redraw_plot(self, sim):\n        self.update_cell_positions(sim)\n        cell_scatter_new = self.ax.scatter(self.cell_x, self.cell_y, c=self.cell_stickiness, cmap='inferno', s=50, edgecolor='white', vmin=0, vmax=CELL_STICKINESS_HIGH*1.2)\n        if(DRAW_ARROW): \n            cell_quiver_new = self.ax.quiver(self.cell_x, self.cell_y, self.cell_vx * 0.15, self.cell_vy * 0.15, angles='xy', scale_units='xy', scale=0.02, color='darkblue')\n            self.cell_quiver.remove()\n            self.cell_quiver = cell_quiver_new\n        self.cell_scatter.remove()\n        self.fig.canvas.draw_idle()\n        self.cell_scatter = cell_scatter_new\n        self.grid_im.remove()\n        self.grid_im = self.ax.imshow(sim.grid.T, extent=(0, WORLD_SIZE, 0, WORLD_SIZE), origin='lower', cmap='viridis', alpha=1.0)\n        \n        plt.pause(0.01)\n            \n            \n# 4. Execute the main loop\nif __name__ == \"__main__\":\n    # with cProfile.Profile() as pr:\n        main()\n        # pr.print_stats()",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#exploring-the-full-javascript-model-with-evolution",
    "href": "evo_practical_1.html#exploring-the-full-javascript-model-with-evolution",
    "title": "17  Practical 1",
    "section": "17.12 Exploring the full Javascript model with evolution",
    "text": "17.12 Exploring the full Javascript model with evolution\nThe full model is implemented in Javascript, and can be found here.\nIn this full model, cells also reproduce every once in a while (when a “season” ends). Their reproductive success is shaped by the amount of resources at that position. Every time a cell reproduces there it inherits the parents stickiness, but it can also change this value a bit. This way, stickiness is an “evolvable” property on which natural selection will act. How much each cell is attracted to nearby cells depends on an internal “stickiness” parameter. Let the simulation run for some time.\n\nExercise 17.2 (The evolution of stickiness) \n\nWhat happens to the evolution of stickiness?\nIdentify multiple advantages and disadvantages of stickiness.\nGiven your answer in b., can you name an important parameter that may determine the balance bewteen the advantages and disadvantages of stickiness? See if you can test it using the options provided.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_1.html#footnotes",
    "href": "evo_practical_1.html#footnotes",
    "title": "17  Practical 1",
    "section": "",
    "text": "The code also contains a Visualisation class that uses the matplotlib library to draw the cells and their movement, which we have tuned to speed things up a bit. You do not need to understand this part of the code, but if you are interested feel free to check it out.↩︎",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Practical 1</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html",
    "href": "evo_practical_2.html",
    "title": "18  Practical 2",
    "section": "",
    "text": "18.1 Genotypes, phenotypes, and evolutionary algorithms\nNear the end of the lecture, we discussed the differences between the genotype (that which mutates) and the phenotype (that which is selected). Although you have likely already heard about these concepts, how can we study them in evolutionary models? During this practical, you will write your own evolutionary algorithms of increasing complexity, in order to learn about these topics. By the end of this practical, you should understand why the translation from genotype to phenotype (often referred to as the genotype-phenotype map) is such an important concept in evolutionary biology.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#simple-model-where-fitness-as-a-number",
    "href": "evo_practical_2.html#simple-model-where-fitness-as-a-number",
    "title": "18  Practical 2",
    "section": "18.2 Simple model where fitness as a number",
    "text": "18.2 Simple model where fitness as a number\nIn the introduction of this course part on evolution, we have already looked at as simple “Moran process”:\n\nStart with a population of individuals, each with a fitness value.\nSelect individuals based on their fitness to reproduce.\nReplace a random individual with this newly generate offspring.\nWith a small probability, modify the ‘fitness’ value of the newborn.\n\nAnd so on.\nWith a Moran process, competition between individuals is modelled in a very indirect (“implicit”) way. By always selecting fit individuals, and removing a random other, any individual in the populations could be replaced by another individual, which statistically is a fitter individual. One could thus say that “everyone is competing with everyone”. A different method is often applied in spatially structured models, as in this case only nearby individuals are competing. Then, we could sample who wins from an imaginary roulette wheel:\n\nAs can be seen, not all individual have the same size on the roulette wheel. That depicts differences in their growth rates, biomass, or other approximations of “fitness”. Also, the roulette wheel contains an area (shown in black) that shapes the chance that nobody reproduces. We will try and implement this rule to let individuals reproduce based on their fitness, but with only 10 competitors at a time. Let’s start with a code where individuals have a “fitness” value, but it not yet used for selection (see below). Read/test this code thoroughly before you move on to the next section.\n\n\n\n\n\n\nCODE FOR “fitness without fitness”\n\n\n\n\n\nimport random\nimport math\nimport matplotlib.pyplot as plt\n\n# Set the random number seed for reproducibility\nrandom.seed(0)\n\nplt.ion()  # Enable interactive plotting\n\n# --- PARAMETERS ---\ninitial_fitness = 0.1            # Starting fitness for all individuals\npopulation_size = 500             # Number of individuals (should be a square number for grid mode)\ngenerations = 20000               # Number of generations to simulate\nmutation_rate = 0.005            # Probability of mutation per reproduction event\nsample_interval = 5               # How often to sample and plot data\n\n# --- INITIALIZATION ---\n# Create initial population: all individuals start with the same fitness\npopulation = [initial_fitness for _ in range(population_size)]\n\n# Lists to track average fitness and diversity over time\navg_fitness = []\ndiversity_over_time = []\n\n# --- CORE FUNCTIONS ---\n\ndef mutate(fitness, rate=mutation_rate):\n    \"\"\"Mutate the fitness value with a given probability.\"\"\"\n    if random.random() &lt; rate:\n        # Fitness changes by a random value in [-0.1, 0.1], clipped to [0, 1]\n        return min(1.0, max(0.0, fitness + random.uniform(-0.1, 0.1)))\n    return fitness\n\ndef calculate_diversity(population):\n    \"\"\"NOT YET IMPLEMENTED! Calculate diversity as the standard deviation of fitness values.\"\"\"\n    return 0 \n\n# --- PLOTTING SETUP ---\nfig, ax1 = plt.subplots(figsize=(12, 8))\nax1.set_xlabel(\"Generation\")\nax1.set_ylabel(\"Average Fitness\", color='tab:blue')\nax1.set_ylim(0, 1)\nline1, = ax1.plot([], [], color='tab:blue', linewidth=2, label='Fitness')\nax1.tick_params(axis='y', labelcolor='tab:blue')\n\n# Second y-axis for diversity\nax2 = ax1.twinx()\nax2.set_ylabel(\"Diversity\", color='tab:green')\nline2, = ax2.plot([], [], color='tab:green', linestyle=':', linewidth=2, label='Diversity')\nax2.tick_params(axis='y', labelcolor='tab:green')\n\nfig.suptitle(\"Evolution Toward Fitness 1\")\nfig.tight_layout()\nfig.legend(loc='upper right')\nplt.grid(True)\nplt.draw()\n\n# --- EVOLUTION LOOP ---\nbest_fitness = -1\nfound = False\n\nfor gen in range(generations):\n    total_fit = sum(population)\n    best = max(population)\n    # Print when a perfect solution is found\n    if best == 1 and not found:\n        found = True\n        print(\"Found perfect solution at generation\", gen)\n        \n    # Sample and plot data at intervals\n    if gen % sample_interval == 0:\n        avg_fitness.append(total_fit / population_size)\n        diversity_over_time.append(calculate_diversity(population))\n        x_vals = [i * sample_interval for i in range(len(avg_fitness))]\n        line1.set_data(x_vals, avg_fitness)\n        line2.set_data(x_vals, diversity_over_time)\n        ax1.relim(); ax1.autoscale_view()\n        ax2.relim(); ax2.autoscale_view()\n        fig.suptitle(f\"Best Fitness: {best:.2f}\", fontsize=14)\n        plt.pause(0.01)\n        \n\n    # --- MORAN PROCESS ---\n    # For each individual, perform a reproduction event\n    for _ in range(100):  # 100 competition events per generation\n        # Select 1 random individual for replication\n        probs = [1 for fit in population] # All probability weights are equal (1.0)\n        parent_idx = random.choices(range(len(population)), weights=probs)[0] # Grab one random individual based on an unweighted list...\n        # Select individual to be replaced (uniform random)\n        dead_idx = random.randrange(len(population))\n        # Copy population for next generation\n        new_pop = population.copy()\n        # Offspring replaces the dead individual (with possible mutation)\n        new_pop[dead_idx] = mutate(population[parent_idx])\n        population = new_pop\n\ninput(\"\\nSimulation complete. Press Enter to exit plot window...\")",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#making-a-roulette-wheel-with-everyone-in-it",
    "href": "evo_practical_2.html#making-a-roulette-wheel-with-everyone-in-it",
    "title": "18  Practical 2",
    "section": "18.3 Making a roulette wheel with everyone in it",
    "text": "18.3 Making a roulette wheel with everyone in it\nIf you have read the code, you will see that we can pass a list of weights to the function random.choices, to determine who is most likely to be sampled. Currently, all the weights are set to 1:\nprobs = [1 for fit in population] # All probability weights are equal (1.0)\n\nRun the code with the current (all equal) weights. What happens?\nModify this line of code to take the fitness values as the weight, rather than 1. (hint: this is a VERY small change in the code).",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#a-roulette-wheel-of-a-subset-of-individuals",
    "href": "evo_practical_2.html#a-roulette-wheel-of-a-subset-of-individuals",
    "title": "18  Practical 2",
    "section": "18.4 A roulette wheel of a subset of individuals",
    "text": "18.4 A roulette wheel of a subset of individuals\nInstead of letting everyone reproduce, let us modify the code to only sample from a smaller list of ‘competitors’, and spin a virtual roulette wheel to determine who wins. There are many ways to implement this, but here’s how we will do it. We will sample N individuals from the population, and implement the following algorithm:\n\nSelect a random subset of N individuals from the population.\nTake/compute the fitness of each selected individual.\nAdd a reproduction-skip option with a fixed weight.\nChoose one individual or the skip option using weighted random selection.\nIf an individual was chosen, mutate it and replace a random individual in the population.\n\nBelow, there’s a small snippet of code doing what is explained above1. The variable no_reproduction_chance is the fixed weight that nobody gets to reproduce:\n\n\n\n\n\n\nRoulette wheel algorithm\n\n\n\n\n\n  tournament_size = 10  \n  no_reproduction_chance = 1\n  \n  competitors = random.sample(population, tournament_size)\n  # Make a list of their fitness values\n  fitness_values = [fit for fit in competitors]\n  total = sum(fitness_values)\n  # Add a \"no reproduction\" dummy competitor with fitness = 0\n  competitors_with_dummy = competitors + [None]\n  probs = [f / total for f in fitness_values] + [no_reproduction_chance]\n  winner = random.choices(competitors_with_dummy, weights=probs, k=1)[0]\n  if winner is not None:\n      # Mutate winner to produce offspring\n      offspring = mutate(winner)\n      remove_idx = random.randrange(len(population))\n      population[remove_idx] = offspring  \n        \n\n\n\nAfter you understand the roulette wheel algorithm, do the following exercise:\n\nExercise 18.1 (Questions about the roulette wheel) \n\nLet’s imagine a moment where the roulette wheel contains only 10 highly unfit individuals (e.g. all fitness values are 0.01). What is the chance that someone will reproduce? (you don’t have to calculate it, but give your reasoning)\nAnswer the same question as in a., but now imagine that all 10 individuals have a fitness value of 1.\nAnswer question b. and c. again, but now assume that no_reproduction_chance is equal to 0.\nDescribe what the no_reproduction_chance parameter does in biological terms.\nSpatially structured populations are often placed on a grid. Describe how you could implement a roulette wheel to resolve local competition, e.g. when an empty grid point is competed for by the neighbours.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#diversity-patterns",
    "href": "evo_practical_2.html#diversity-patterns",
    "title": "18  Practical 2",
    "section": "18.5 Diversity patterns",
    "text": "18.5 Diversity patterns\nModify the function calculate_diversity to calculate the diversity of the population as the standard deviation of the fitness values.\n\nExercise 18.2 (Questions about the roulette wheel) \n\nUse a low mutation rate and study the dynamics of diversity. Describe the pattern verbally.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#evolving-a-dna-sequence",
    "href": "evo_practical_2.html#evolving-a-dna-sequence",
    "title": "18  Practical 2",
    "section": "18.6 Evolving a DNA sequence",
    "text": "18.6 Evolving a DNA sequence\nA big problem with the previous model is there is no true distinction between genotype (that which mutates) and phenotype (that which is selected). Let us try and adapt the model to be more biologically meaningful, by making each individual represented by a DNA sequence. Copy the following code:\n\n\n\n\n\n\nStarting code for “evolving a DNA sequence”\n\n\n\n\n\nimport random\nimport math\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# set the random number seed\nrandom.seed(0)\n\nplt.ion()  # Enable interactive mode\n\n# Parameters\nalphabet = \"ATCG\"\ntarget_sequence = \"GATGCGCGCTGGATTAAC\"  # Example target sequence\ndna_length = len(target_sequence)\ntarget_length = len(target_sequence)\n\n# Simulation settings\npopulation_size = 500  # must be a square number for grid mode\ngenerations = 20000\nmutation_rate = 0.001\nsample_interval = 5\nsample_size = population_size\nno_reproduction_chance = 0.1\n\n# Core functions\ndef fitness(dna):\n    return 1 - sum(a != b for a, b in zip(dna, target_sequence)) / target_length\n\ndef mutate(dna, rate=mutation_rate):\n    return ''.join(\n        random.choice([b for b in alphabet if b != base]) if random.random() &lt; rate else base\n        for base in dna\n    )\n\ndef count_beneficial_mutations(dna):\n    f0 = fitness(dna)\n    count = 0\n    for i in range(len(dna)):\n        for b in alphabet:\n            if b != dna[i]:\n                mutant = dna[:i] + b + dna[i+1:]\n                if fitness(mutant) &gt; f0:\n                    count += 1\n    return count\n\ndef diversity(pop):\n    counts = {}\n    for ind in pop:\n        counts[ind] = counts.get(ind, 0) + 1\n    total = len(pop)\n    return -sum((c/total) * math.log(c/total + 1e-9) for c in counts.values()) if total &gt; 0 else 0\n\n# Initialize population\ninitial_sequence = \"GATAGCGAAGTTTAGCCG\" # far from target (only first 3 are correct)\npopulation = [initial_sequence for _ in range(population_size)]\n\navg_fitness = []\navg_beneficial = []\ndiversity_over_time = []\nbest_individuals = []\n\ndef get_neighbors(i, j):\n    return [(x % side, y % side)\n            for x in range(i-1, i+2)\n            for y in range(j-1, j+2)]\n\n# Initialize interactive plot\nfig, ax1 = plt.subplots(figsize=(12, 8))\nax1.set_xlabel(\"Generation\")\nax1.set_ylabel(\"Average Fitness\", color='tab:blue')\nax1.set_ylim(0, 1)\nline1, = ax1.plot([], [], color='tab:blue', linewidth=2, label='Fitness')\nax1.tick_params(axis='y', labelcolor='tab:blue')\n\nax2 = ax1.twinx()\nax2.set_ylabel(\"Beneficial Mutations / Diversity\", color='tab:purple')\nline2, = ax2.plot([], [], color='tab:purple', linestyle='--', linewidth=2, label='Beneficial Mutations')\nline3, = ax2.plot([], [], color='tab:green', linestyle=':', linewidth=2, label='Diversity')\nax2.tick_params(axis='y', labelcolor='tab:purple')\nfig.suptitle(\"Evolution Toward Target Sequence\")\nfig.tight_layout()\nax2.set_ylim(0, 20)\nfig.legend(loc='upper right')\nplt.grid(True)\nplt.draw()\n\nbest_seq = \"\"\nbest_score = -1\nfound = False\n\n# Evolution loop\nfor gen in range(generations):\n    fitnesses = [fitness(ind) for ind in population]\n    total_fit = sum(fitnesses)\n    best = max(fitnesses)\n    if(best == 1 and not found):\n        found = True\n        print(\"Found perfect solution at generation\", gen)\n        \n    if gen % sample_interval == 0:\n        sample = random.sample(population, sample_size)\n        avg_beneficial.append(sum(count_beneficial_mutations(ind) for ind in sample) / sample_size)\n        diversity_over_time.append(diversity(population))\n\n        # Update plot data\n        line1.set_data(range(len(avg_fitness)+1), avg_fitness + [sum(fitnesses)/population_size])\n        line2.set_data(range(len(avg_beneficial)), avg_beneficial)\n        line3.set_data(range(len(diversity_over_time)), diversity_over_time)\n        ax1.relim(); ax1.autoscale_view()\n        ax2.relim(); ax2.autoscale_view()\n        best = max(population, key=fitness)\n        fig.suptitle(f\"Best: {best} (target: {target_sequence})\", fontsize=14)\n        plt.pause(0.01)\n\n    else:\n        avg_beneficial.append(avg_beneficial[-1])\n        diversity_over_time.append(diversity_over_time[-1])\n\n    # Tournament selection (as in evolving_fitness_final.py)\n    new_pop = []\n    tournament_size = 10  # can be adjusted\n\n    for _ in range(population_size):\n        # Select tournament_size individuals randomly\n        competitors = random.sample(population, tournament_size)\n        # Pick the one with highest fitness\n        fitness_values = [fitness(ind) for ind in competitors]\n        total = sum(fitness_values)\n        \n        probs = [f / total for f in fitness_values]\n        winner = random.choices(competitors, weights=probs, k=1)[0]\n        # Mutate winner to produce offspring\n        offspring = mutate(winner)\n        new_pop.append(offspring)\n\n    population = new_pop\n\n    avg_fitness.append(sum(fitness(ind) for ind in population) / population_size)\n    if gen % 250 == 0:\n        best = max(population, key=fitness)\n        best_individuals.append((gen, best))\n\ninput(\"\\nSimulation complete. Press Enter to exit plot window...\")\n\n\n\nAnswer the following questions using the options available in the model:\n\nExercise 18.3 (Evolving DNA)  \n\nRun the code. What does the new (dashed blue) line represent? Do you understand how is changes over time?\n\nThe program reports after how many generations it manages to find the target sequence. With default settings this can take a long time… (default: 4633 generations)\n\nModify the mutation rate to see how it affects the time to find the target sequence. Try different mutation rates between 0.0001 and 0.1. Keep track of both how long (number of generations) it takes to find the target, and how fit the population is once the target is found. What do you observe?\nDiversity is no longer calculated as the standard deviation in fitness, but as the Shannon diversity of all present sequences (although it is not super complex, you do not need to fully understand this function). Because of this, the exact number (quantities) cannot be compared to our ealrier model. Do you see a qualitative differences?\nStudy how fitness is calculated in this model. Is there a distinction between genotype en phenotype? Why/why not?",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#evolving-a-protein-sequence",
    "href": "evo_practical_2.html#evolving-a-protein-sequence",
    "title": "18  Practical 2",
    "section": "18.7 Evolving a protein sequence",
    "text": "18.7 Evolving a protein sequence\nNext we will extend the simulation a little more. The individual genotypes will still be represented as a DNA sequence, but before evaluating fitness this will be translated into a protein sequence. To do so, the code first defines the codon table (which we of course all know by heart =)), and then translates the DNA sequence into a protein sequence. The protein sequence is then used to calculate the fitness of the individual, which is based on how well the protein sequence matches a target protein sequence. The code is as follows:\n\n\n\n\n\n\nStarting code for evolving a protein sequence\n\n\n\n\n\nimport random\nimport math\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# set the random number seed\nrandom.seed(0)\n\nplt.ion()  # Enable interactive mode\n\n# Codon table\ncodon_table = {\n    'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L', 'CTT': 'L', 'CTC': 'L', 'CTA': 'L', 'CTG': 'L',\n    'ATT': 'I', 'ATC': 'I', 'ATA': 'I', 'ATG': 'M',\n    'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V',\n    'TCT': 'S', 'TCC': 'S', 'TCA': 'S', 'TCG': 'S', 'AGT': 'S', 'AGC': 'S',\n    'CCT': 'P', 'CCC': 'P', 'CCA': 'P', 'CCG': 'P',\n    'ACT': 'T', 'ACC': 'T', 'ACA': 'T', 'ACG': 'T',\n    'GCT': 'A', 'GCC': 'A', 'GCA': 'A', 'GCG': 'A',\n    'TAT': 'Y', 'TAC': 'Y', 'CAT': 'H', 'CAC': 'H',\n    'CAA': 'Q', 'CAG': 'Q', 'AAT': 'N', 'AAC': 'N',\n    'AAA': 'K', 'AAG': 'K', 'GAT': 'D', 'GAC': 'D',\n    'GAA': 'E', 'GAG': 'E', 'TGT': 'C', 'TGC': 'C',\n    'TGG': 'W', 'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R', 'AGA': 'R', 'AGG': 'R',\n    'GGT': 'G', 'GGC': 'G', 'GGA': 'G', 'GGG': 'G',\n    'TAA': '*', 'TAG': '*', 'TGA': '*'\n}\n\n# Parameters\nalphabet = \"ATCG\"\ntarget_protein = \"DARWIN\"\ndna_length = len(target_protein)*3\ntarget_length = len(target_protein)\n\n# Simulation settings\npopulation_size = 625  # must be a square number for grid mode\ngenerations = 20000\nmutation_rate = 0.0005   \nsample_interval = 5\nsample_size = population_size\nno_reproduction_chance = 0.01\n\n# Core functions\ndef translate(dna):\n    return ''.join(codon_table.get(dna[i:i+3], '?') for i in range(0, len(dna), 3))\n\ndef fitness(dna):\n    protein = translate(dna)\n    return 1 - sum(a != b for a, b in zip(protein, target_protein)) / target_length\n\ndef mutate(dna, rate=mutation_rate):\n    return ''.join(\n        random.choice([b for b in alphabet if b != base]) if random.random() &lt; rate else base\n        for base in dna\n    )\n\ndef count_beneficial_mutations(dna):\n    f0 = fitness(dna)\n    count = 0\n    for i in range(len(dna)):\n        for b in alphabet:\n            if b != dna[i]:\n                mutant = dna[:i] + b + dna[i+1:]\n                if fitness(mutant) &gt; f0:\n                    count += 1\n    return count\n\ndef diversity(pop):\n    counts = Counter(pop)\n    total = len(pop)\n    return -sum((c/total) * math.log(c/total + 1e-9) for c in counts.values()) if total &gt; 0 else 0\n\n# Initialize population\ninitial_sequence = ''.join(random.choice(alphabet) for _ in range(dna_length))\npopulation = [initial_sequence for _ in range(population_size)]\n\navg_fitness = []\navg_beneficial = []\ndiversity_over_time = []\nbest_individuals = []\n\n# Grid setup\nside = int(math.sqrt(population_size))\nassert side * side == population_size, \"Population size must be a square number for grid mode\"\n\ndef get_neighbors(i, j):\n    return [(x % side, y % side)\n            for x in range(i-1, i+2)\n            for y in range(j-1, j+2)]\n\n# Initialize interactive plot\nfig, ax1 = plt.subplots(figsize=(12, 8))\nax1.set_xlabel(\"Generation\")\nax1.set_ylabel(\"Average Fitness\", color='tab:blue')\nax1.set_ylim(0, 1)\nline0, = ax1.plot([], [], color='black', linewidth=1, label='Max fitness')\nline1, = ax1.plot([], [], color='tab:blue', linewidth=2, label='Fitness')\nax1.tick_params(axis='y', labelcolor='tab:blue')\n\nax2 = ax1.twinx()\nax2.set_ylabel(\"Beneficial Mutations / Diversity\", color='tab:purple')\nline2, = ax2.plot([], [], color='tab:purple', linestyle='--', linewidth=2, label='Beneficial Mutations')\nline3, = ax2.plot([], [], color='tab:green', linestyle=':', linewidth=2, label='Diversity')\nax2.tick_params(axis='y', labelcolor='tab:purple')\nfig.suptitle(\"Evolution Toward \" + str(target_protein))\nfig.tight_layout()\nax2.set_ylim(0, 5)\nfig.legend(loc='upper right')\nplt.grid(True)\nplt.draw()\n\nbest_seq = \"\"\nbest_score = -1\nbest_fitnesses = []\nfound = False\n\n# Evolution loop\nfor gen in range(generations):\n    fitnesses = [fitness(ind) for ind in population]\n    total_fit = sum(fitnesses)\n    best = max(fitnesses)\n    best_fitnesses.append(best)\n    if(best == 1 and not found):\n        found = True\n        print(\"Found perfect solution at generation\", gen)\n        \n    if gen % sample_interval == 0:\n        sample = random.sample(population, sample_size)\n        avg_beneficial.append(sum(count_beneficial_mutations(ind) for ind in sample) / sample_size)\n        diversity_over_time.append(diversity(population))\n\n        # Update plot data\n        line0.set_data(range(len(avg_fitness)+1), best_fitnesses)\n        line1.set_data(range(len(avg_fitness)+1), avg_fitness + [sum(fitnesses)/population_size])\n        line2.set_data(range(len(avg_beneficial)), avg_beneficial)\n        line3.set_data(range(len(diversity_over_time)), diversity_over_time)\n        ax1.relim(); ax1.autoscale_view()\n        ax2.relim(); ax2.autoscale_view()\n        best = max(population, key=fitness)\n        fig.suptitle(f\"Best: {translate(best)} (target: {target_protein})\", fontsize=14)\n        plt.pause(0.01)\n\n    else:\n        avg_beneficial.append(avg_beneficial[-1])\n        diversity_over_time.append(diversity_over_time[-1])\n\n    new_pop = []\n    tournament_size = 10  # can be adjusted\n    \n    for _ in range(population_size):\n        # Select tournament_size individuals randomly\n        competitors = random.sample(population, tournament_size)\n        # Pick the one with highest fitness\n        fitness_values = [fitness(ind) for ind in competitors]\n        total = sum(fitness_values)\n        \n        probs = [f / total for f in fitness_values]\n        winner = random.choices(competitors, weights=probs, k=1)[0]\n        # Mutate winner to produce offspring\n        offspring = mutate(winner)\n        new_pop.append(offspring)\n\n    population = new_pop\n\n\n    avg_fitness.append(sum(fitness(ind) for ind in population) / population_size)\n    if gen % 250 == 0:\n        best = max(population, key=fitness)\n        best_individuals.append((gen, translate(best)))\n\ninput(\"\\nSimulation complete. Press Enter to exit plot window...\")\n\n\n\nAnswer the following question about the model:\n\nExercise 18.4 (Evolving protein sequences)  \n\nAnother line was added to the model. What new information can you obtain from analysing this line?\nStudy carefully how the other lines (also present in previous models) change over time. What do you observe? Try and capture what you see into words.\nIn biology, multiple genotypes can translate to the same phenotype (this is called a many-to-one genotype-phenotype map), or alternatively, one genotype can produce multiple phenotype (this is called phenotypic plasticity, or a one-to-many genotype-phenotype map). Which genotype-phenotype (GP) mapping applies to this model? Why?\nBonus question for motivated students modify the code to include a second target protein sequence, and alternate between the two targets. If you see something interesting, please share it with the class!",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_2.html#footnotes",
    "href": "evo_practical_2.html#footnotes",
    "title": "18  Practical 2",
    "section": "",
    "text": "Note that this is from the full code, so this code does not work stand-alone↩︎",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Practical 2</span>"
    ]
  },
  {
    "objectID": "evo_practical_3.html",
    "href": "evo_practical_3.html",
    "title": "19  Practical 3",
    "section": "",
    "text": "19.1 Building a model from scratch\nOver the last weeks you have been given many model of biology, and you have modified or extended upon them. For this practical, I will give you a only a description. Your challenge will be to see how far you get in trying to get this model working yourself. I advice you use AI-assisted programming only to solve small steps, otherwise you have no clue what you are doing. But if you try and do everything yourself, it may take a little long.\nAt the end of the pratical, we will compare different implementations by students, as well as my implementation. Hopefully, we will see some generic patterns, because the model description should be good enough to give “similar models”. The description should be “vague enough” to lead to some differences, but “precise enough” to yield similar results. This is an experiment in and of itself. So let’s see :’)\nNote that I also do not yet know exactly what will happen in this simulation (although I have tried it out), so I’m hoping we will learn some cool stuff together!",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "evo_practical_3.html#simulating-a-simple-microbial-ecosystem-with-public-goods",
    "href": "evo_practical_3.html#simulating-a-simple-microbial-ecosystem-with-public-goods",
    "title": "19  Practical 3",
    "section": "19.2 Simulating a simple microbial ecosystem with “public goods”",
    "text": "19.2 Simulating a simple microbial ecosystem with “public goods”\n\nModel description\nMicrobes often produce public goods, from which surrounding microbes can benefit. This can lead to interesting dynamics, such as cooperation and competition. Most models however consider on 1 public good at a time, which leads to limited diversity (a producer, and a non-producer may or may not coexist). Here, we will an ecosystem with many public goods, and simulate them on a grid.\nAn individual microbe will carry a “genome” that is represented by a binary string (101010010011). Each position in the string represents a public good, and whether the individual can produce it (1) or not (0). The individual can rely on other individuals to produce public goods.\nWe will simulate individuals (microbial cells) reproducing and dying on a grid. A grid point either contains an individual, or it is empty. Every empty point, will be competed for by individuals that are in that neighbourhood. The neighbourhood is defined as the 8 surrounding grid points (this is called the “Moore” neighbourhood). The cells can only replicate if they have all the public goods they need, which means that they can rely on other individuals in their neighbourhood to produce them. If they do not have all public goods available, they cannot replicate. The “winner” from these (max) 8 viable competitors will be determined by a roulette wheel selection, where the relative probability is determined by their fitness:\n\\[\nF_i = 1 - c \\cdot \\sum({bitstring})\n\\]\nIn other words, fitness goes down as the number of public goods produced increases, and there is a cost \\(c\\) associated with producing each public good. Make sure this roulette wheel contains a probability that nobody wins, such that highly unfit individuals are less likely to replicate than highly fit individuals (also see earlier practicals).\nThe individual that replicates, can undergo mutations in the bitstring (gene loss and gene gain). Assume gene loss is more likely than gene gain (initial parameters to explore are summarised below)\nFinally, implement a function that allows you to mix the grid (all individuals are placed in a random position).\n\n\nModel output\nThe model will have the following output: a grid that is coloured by the number of public goods produced (for consistency, let’s all use a ‘viridis’ scale), and a line graph that plots the total population sizes, as well as the population sizes of species producing 0 public goods, 1 public good, 2 public goods, etc. (see Figure 19.1)\n\n\nParameters to start out with\n\nGrid size: 50 x 50\nInitial population: produces all public goods (1111…1)\nDeath rate: 0.1\nCost (c): 0.05\nBitstring 1 to 0 mutation (losing a gene): 0.01\nBitstring 0 to 1 mutation (gaining a gene): 0.001\nNumber of public goods (i.e. bitstring length): 10\n“No-event” size of roulette wheel: 1\n\n\n\n\n\n\n\nFigure 19.1: Example of what the simulation could look like\n\n\n\n\n\nProposed experiments\nTry investigating how the model behaves with different values of \\(c\\) (the cost of producing public goods). Can you explain what happens at \\(c=0.0\\)?\nTry studying the effect of mixing the whole grid every timestep, such that neighbourhoods are constantly “randomised”. Look at the population size, as well as the distribution of different types. Can you explain the observations in biological terms?\nTry studying what happens at different mutation rates.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Practical 3</span>"
    ]
  },
  {
    "objectID": "evo_answers.html",
    "href": "evo_answers.html",
    "title": "20  Answers exercises",
    "section": "",
    "text": "20.1 Answers to Evolution Practical 1",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Answers exercises</span>"
    ]
  },
  {
    "objectID": "evo_answers.html#answers-to-evolution-practical-1",
    "href": "evo_answers.html#answers-to-evolution-practical-1",
    "title": "20  Answers exercises",
    "section": "",
    "text": "Questions Exercise 17.1\n\nFor this, you can simply multiply the velocity components every timestep by a value &gt; 1. For example:\n# Accellerate the velocity\nvx *= 1.01\nvy *= 1.01\nNote that this gets out of hand quite quickly.\nTo do this, we need to store the new values in a temporary variable, and then assign them to the original variables. This is necessary because while we first modify vx, we still want to use the ‘old’ value of vx to calculate the new vy. The following code rotates the velocity vector by 0.05 radians:\n# Rotate the velocity vector by a small angle \nvxnew = vx * np.cos(0.05) - vy * np.sin(0.05)\nvynew = vx * np.sin(0.05) + vy * np.cos(0.05)\nvx, vy = vxnew, vynew\nIf you run this code, you will see that the dot will go in circles.\nWhile the code above stores x, y, vx, and vy as a ‘global variables’, this is not good if we have many individuals. Instead, we can store the state of each individual in a list, dictionary, or a class. For example, we make a class ‘cell’ and store 100 of these ‘cells’ in a large list:\nclass Cell:\n    def __init__(self, x, y, vx, vy):\n        self.x = x\n        self.y = y\n        self.vx = vx\n        self.vy = vy\n\n# Create 100 cells with random positions and 0 velocity\ncells = [Cell(np.random.rand(), np.random.rand(), 0.0, 0.0) for _ in range(100)]\n\n\n\nMoving the target (Section 17.4)\nA working code to steer the individuals towards the target is shown below. Note that the acceleration that is applied is only small, otherwise the individuals will move in a straight line towards the target very rapidly.\ndef move_towards_dot(self, cell):\n   \"\"\"Apply forces in the direction of the dot.\"\"\"\n   # Calculate dx and dy\n   dx = self.target_position[0] - cell.x\n   dy = self.target_position[1] - cell.y\n   # Calculate the distance to the target (pythagorean theorem)\n   distance = np.sqrt(dx**2 + dy**2)\n   \n   # Normalize dx and dy \n   dx /= distance\n   dy /= distance\n   # Apply a small force towards the target\n   cell.ax += dx * 0.01\n   cell.ay += dy * 0.01\n\n\nReproduction (Section 17.5)\nA working code to reproduce a cell is shown below. Note that I decided to first throw an individual away, and then add the newborn individual (instead of the other way around). This ensures the newborn cannot be immediately thrown away, which would be a rather pointless event.\ndef reproduce_cell(self, cell):\n        # Reproduce: Create a new cell with the same properties as the current cell\n        angle = np.random.uniform(0, 2 * np.pi)\n        radius = np.random.uniform(0.05, 1.5)\n        new_x = cell.x + radius * np.cos(angle)\n        new_y = cell.y + radius * np.sin(angle)\n        new_cell = Cell(new_x, new_y, cell.vx, cell.vy)\n        random_cell = np.random.choice(self.cells)   \n        self.cells.remove(random_cell)\n        self.cells.append(new_cell)\n\n\nCollision (Section 17.6)\nA working code for cell-cell collision is shown below. Note that we apply a large force as we want this force to be able to overpower other forces that make the cells overlap.\n def avoid_collision(self, cell):\n        \"\"\"Avoidance forces to prevent cells from colliding.\"\"\"\n        for other_cell in self.cells:\n            if other_cell is not cell:\n                # Calculate the distance between the two cells\n                dx = cell.x - other_cell.x\n                dy = cell.y - other_cell.y\n                distance = np.sqrt(dx**2 + dy**2)\n\n                # If the cells are too close, apply a repulsion force\n                if distance &lt; 5.0 and distance &gt; 0:  # Threshold for \"too close\"\n                    # repulsion force proportional to the inverse of the distance\n                    force_magnitude = (5.0 - distance) / distance\n                    cell.ax += force_magnitude * dx  * 100\n                    cell.ay += force_magnitude * dy * 100\n\n\nA resource peak (Section 17.7)\nA working code to implement a resource peak (with optional noise set to 0 by default) is shown below:\ndef fill_grid(self, grid, mean_x, mean_y, std_dev, noise=0):\n        \"\"\"Creates a Gaussian distribution with noise on the grid.\"\"\"\n        for i in range(WORLD_SIZE):\n            for j in range(WORLD_SIZE):\n                x = i / (WORLD_SIZE - 1)\n                y = j / (WORLD_SIZE - 1)\n                distance_squared = (x - mean_x)**2 + (y - mean_y)**2\n                grid[i, j] = np.exp(-distance_squared / (2 * std_dev**2)) * np.random.uniform(0.0, 1.0)**noise\n\n        # Normalize the grid to keep the total resource concentration the same\n        grid /= np.sum(grid)\n        self.grid = grid\n\n\nRun and tumble (Section 17.8)\nA working code to implement a run-and-tumble mechanism shown below:\ndef find_peak(self, cell):\n        # Convert cell position to grid indices, as well as the previous position\n        grid_x = int(cell.x) % WORLD_SIZE\n        grid_y = int(cell.y) % WORLD_SIZE\n        next_x = (int(cell.x + 10*cell.vx) + WORLD_SIZE) % WORLD_SIZE \n        next_y = (int(cell.y + 10*cell.vy) + WORLD_SIZE) % WORLD_SIZE \n        # Get the resource value at cell's position, as well as the next position\n        resource_value = self.grid[grid_x, grid_y]\n        resource_next = self.grid[next_x, next_y]\n        \n        # Check if the cell is moving in the right direction\n        if resource_next &gt; resource_value:\n            # Moving in the right direction: small random adjustment\n            angle = np.random.uniform(-0.1, 0.1)  # Small angle change\n        else:\n            # Moving in the wrong direction: large random adjustment\n            angle = np.random.uniform(-np.pi*1.0, np.pi*1.0)  # Large angle change\n        \n        # Rotate the velocity vector by the angle calculated\n        new_vx = cell.vx * np.cos(angle) - cell.vy * np.sin(angle)\n        new_vy = cell.vx * np.sin(angle) + cell.vy * np.cos(angle)\n    \n        # Update the acceleration with the new velocity vector\n        cell.vx = new_vx\n        cell.vy = new_vy\n        cell.ax += cell.vx\n        cell.ay += cell.vy\n\n\nStickiness (Section 17.9)\nA working code for stickiness is shown below. The force applied here is smaller than the collision force (as said, we want to try and avoid collision even as cells want to move closer to eachother).\ndef stick_to_close(self, cell):\n        \"\"\"Stick to closeby cells.\"\"\"\n        for other_cell in self.cells:\n            if other_cell is not cell:\n                # Calculate the distance between the two cells\n                dx = cell.x - other_cell.x\n                dy = cell.y - other_cell.y\n                distance = np.sqrt(dx**2 + dy**2)\n\n                # If the cells are too close, apply a repulsion force\n                if distance &lt; 12 and distance &gt; 5:  # Threshold for \"close\"\n                    # Calculate the repulsion force proportional to the inverse of the distance\n                    cell.ax -= cell.stickiness * dx *10\n                    cell.ay -= cell.stickiness * dy *10\n\n\nThe evolution of stickiness (Exercise 17.2)\n\nIn the full model, stickiness naturally evolves to be higher. Natural selection therefore favours stickiness. However, it does not keep increasing and it stabilises around 0.25.\nThe advantages of stickiness are that larger groups of cells are better at steering towards the resources. Even if a single cell tries to go in the wrong direction, it will be pulled back. Together, they are less sensitive to the noise. Another distinct advantage is that the stickiest cells are sorted to be in the center of the group (as you have already seen earlier in this course!). That means that even after the peak was found, the stickiest cells have an advantage over the other cells as they can occupy the peak of the resource distribution. The disadvantages of stickiness are that larger groups move more slowly, and that the sticky clusters tend to stay together even if there are many resource peaks (and therewith miss out on resources).\nThe duration of the seasonal cycle is very important. If it is very long, it does not matter that the large clusters move slowly, as they will be better at finding and staying on the peak by being sticky. If the cycle is however very short, it may be more important to be able to move quickly and change direction rapidly. In that case, being too sticky may be a problem. As you modify this parameter in the online model, you will indeed see that shorter seasons mostly cause stickiness to drift close to 0.0, while longer seasons cause stickiness to evolve towards 0.25 or even higher.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Answers exercises</span>"
    ]
  },
  {
    "objectID": "evo_answers.html#answers-to-evolution-practical-2",
    "href": "evo_answers.html#answers-to-evolution-practical-2",
    "title": "20  Answers exercises",
    "section": "20.2 Answers to Evolution Practical 2",
    "text": "20.2 Answers to Evolution Practical 2\n\nQuestions Exercise 18.1\n\nIf we sample 10 unfit individuals, the weight of the no_reproduction_event is proportionally high (the black slice of the roulette wheel is big). Hence, there is only a small chance that anyone will reproduce.\nIf we sample 10 fit individuals (fitness 1), the chances are much higher that someone will reproduce.\nIf the dummy value is 0, the chances that someone will reproduce are the same in both scenarios, as even with very unfit individuals there is no chance that nobody reproduces.\nIn nature, if no individual is sufficiently fit, reproduction may not occur at all. For example, if the competing individuals are bacteria with very low glucose uptake rates, they may not yet be physiologically ready to reproduce. In such cases, population size should remain stable or even decline if death is also occurring. The no_reproduction_event captures this by ensuring that fitness is not judged solely in relative terms against other individuals, but also in absolute terms against environmental demands.\nIf a grid point is empty (contains no individual), make a list of (up to) 8 individuals around that grid point. Apply the roulette wheel for those individuals, and place the ‘winner’ inside the empty grid point.\n\n\n\nQuestions Exercise 18.2\nA snippet to calculate the standard deviation of a population is shown below. Note that this value is already being plotted, so if you modify this function you ought to be able to see what happens immediately.\ndef calculate_diversity(population):\n    \"\"\"Calculate diversity as the standard deviation of fitness values.\"\"\"\n    mean = sum(population) / len(population)\n    variance = sum((x - mean) ** 2 for x in population) / (len(population) - 1)\n    return math.sqrt(variance)\n\nThe green dotted line is the standard deviation of the values in the population (‘diversity’). From this we can see that the population is only breifly diverse whenever a new, fit individual appears. In between these phases, diversity is 0. This makes intuitive (biological) sense, as with a low mutation rate the only moments where there is more than 1 species is during the invasion of a new mutant. During all other phases, there is just a single (fittest) species.\n\n\n\n\nQuestions Exercise 18.3\n\nThe new blue dotted line represents how many mutations are beneficial (towards the target). As the population gets closer to the target, the number of beneficial mutations decreases. As such, this line is a mirror image of the fitness in the population. We will look a bit deeper into this line in the next model.\nGenerally speaking, a higher mutation rate helps to find the target faster. However, with high mutation rates (0.01 or higher), the fitness after the target is found starts to decrease, as individual produce many (unfit) mutants. In fact, if mutation rate is too high (approximately 0.04 or higher), the population fails to find the target at all, as reproduction is too inaccurate! This concept is known as the ‘error threshold’ or the ‘error catastrophe’ in evolutionary biology.\nQualitatively, there is no clear difference to what we saw before: diversity only peaks at moments when there is a new mutant coming in, but otherwise diversity is 0.\nThere is no distinction between genotype and phenotype. Fitness is directly calculated from the DNA sequence, so there is no ‘genotype-to-phenotype mapping’.\n\n\n\nQuestions Exercise 18.4\n\nThe new black line is the maximum fitness in the population. Thanks to this line we can see that, sometimes, an individual is present that is fitter but it does not manage to take over the population. We are dealing with a stochastic process, so this is very natural.\nThe fitness line once again goes in distinct steps. The diversity line (green dotted) has a distinct behaviour compared to earlier models. Instead of only going up during the discovery of a new mutant, it constantly creeps up during periods where fitness does not change. This is because the codon-table is partially redundant: many different DNA sequences can code for the same amino acid sequence, so diveristy increases. However, when a new “fitter” individual comes in, diversity goes down as that individual clonally takes over the population. Then, diversity slowly increases again. A similar pattern is reflected in the line that represents the “beneficial mutations” (blue dotted line). TLDR; even when fitness is not changing there is still a lot going on in this population!\nThis model represents a many-to-one mapping between genotype and phenotype. The DNA sequence (genotype) is translated into an amino acid sequence (phenotype), which is then used to calculate fitness. This means that many different genotypes can lead to the same phenotype, and thus the same fitness. Earlier in this course you have learned about development, and those processes often lead to effects where the same genotype can produce many different shapes (phenotypes).\nBONUS: I have not personally done this, and I do not know the answer to this question yet. However, it is sometimes observed that with many-to-one mapping, populations can because better and better at switching between two alternating targets. This is because the alternating selection pressures make populations move towards genotypes that are “close” to both targets, and because there is some neutrality coding this can be acchieved without losing fitness in either environment. For cool paper on this principle, see Crombach and Hogeweg (2008). I suspect however that our current model will not be able to do the same.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Answers exercises</span>"
    ]
  },
  {
    "objectID": "evo_answers.html#answers-to-evolution-practical-3",
    "href": "evo_answers.html#answers-to-evolution-practical-3",
    "title": "20  Answers exercises",
    "section": "20.3 Answers to Evolution Practical 3",
    "text": "20.3 Answers to Evolution Practical 3\nThis practical is quite open-ended, so instead of answers it is more useful to have a scientific discussion. The image below was first run on a spatially structured grid, but from the dashed line onwards the grid was mixed every timestep. From this we can see that it matters “who you compete with”. On the spatial grid, individuals compete mostly with other individuals of their own species. That means that, on average, they cannot complement each other by providing public goods (they produce the same set!). Because of this, the “omni-producers” (yellow line) dominates, surrounded by a cloud of mutants that rely on other types. The population size fluctuates strongly, as local populations can collapse due to the loss of public goods, typically followed by the “omni-producers” once again invading the available niche space (empty space on the grid).\nWhen mixing the grid every time step, who you interact with is randomised, and individuals can now rely on other genotypes in the population. Although there is some luck involved in this, you can see that the total population (the black line) increases from this point onward. Thus, although the omni-producers are less dominant, statistically individuals are much better off in this mixed world. That said, there is a risk to this mixed population: if the cost of producing public goods is too high, the population can collapse as there is a strong incentive to lose production of public goods and start relying on others. Depending on your implementation, you may find that mixed systems therefor perform better or worse than spatially structured systems. If they behave identically though, let me (Bram) know, as that is something I almost never observe in models like this ;)\n\n\n\nDynamics of the producer-types in a system with 10 ‘public goods’\n\n\n\n\n\n\nCrombach, Anton, and Paulien Hogeweg. 2008. “Evolution of Evolvability in Gene Regulatory Networks.” PLoS Computational Biology 4 (7): e1000112.",
    "crumbs": [
      "IV) Evolution",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Answers exercises</span>"
    ]
  },
  {
    "objectID": "project_1.html",
    "href": "project_1.html",
    "title": "21  Differentiation introduction",
    "section": "",
    "text": "21.1 Equations\nHere’s an equation:\n\\[\n\\frac{\\mathrm{d}N}{\\mathrm{d}t} = rN(1 - \\frac{N}{K})\n\\tag{21.1}\\]\nAnd Equation A.1 is a reference to the equation above.",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "project_1.html#references",
    "href": "project_1.html#references",
    "title": "21  Differentiation introduction",
    "section": "21.2 References",
    "text": "21.2 References\nSee Knuth (1984) for additional discussion of literate programming.",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "project_1.html#syntax-highlighting",
    "href": "project_1.html#syntax-highlighting",
    "title": "21  Differentiation introduction",
    "section": "21.3 Syntax highlighting",
    "text": "21.3 Syntax highlighting\nHere’s some python code:\nimport numpy as np\nnp.random.seed(42)\na = 1 + 2\nb = a + 3\nprint(\"Hello\")",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "project_1.html#visualising-data-r",
    "href": "project_1.html#visualising-data-r",
    "title": "21  Differentiation introduction",
    "section": "21.4 Visualising data (R)",
    "text": "21.4 Visualising data (R)\nHere’s an interactive plot generated with R:",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "project_1.html#a-youtube-clip",
    "href": "project_1.html#a-youtube-clip",
    "title": "21  Differentiation introduction",
    "section": "21.5 A youtube clip:",
    "text": "21.5 A youtube clip:",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "project_1.html#an-iframe-to-a-different-page-e.g.-my-simulations",
    "href": "project_1.html#an-iframe-to-a-different-page-e.g.-my-simulations",
    "title": "21  Differentiation introduction",
    "section": "21.6 An ‘iframe’ to a different page (e.g. my simulations)",
    "text": "21.6 An ‘iframe’ to a different page (e.g. my simulations)\n\n\nMermaid\nDiagrams (Mermaid syntax):\n\n\n\n\n\n\nflowchart TB\nA(Models) --&gt; C(\"Analytical (mathematical)\")\nA --&gt; B(\"Numerical (computational)\")\nB --&gt; F(Individual-based model)\nB --&gt; G(Cellular automaton)\nC --&gt; E(Differential equation)\nC --&gt; D(MAPs)\n\n\n\n\nFigure 21.1: Types of models\n\n\n\n\n\nWhich can be referred to Figure A.1.\n\n\nCallouts\nCall-outs can organise information and highlight important points.\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\n\n\n\nTip 21.1: Cross-Referencing a Tip\n\n\n\nAdd an ID starting with #tip- to reference a tip.\n\n\nSee Tip A.1…\n\n\nHow to format questions/problem sets\n\nExercise 21.1 (Test 1) The equation of any straight line, called a linear equation, can be written as:\n\\[\ny = mx + b\n\\tag{21.2}\\]\nRefer to the equation like this Equation A.2 or like Customlabel A.2.\na. Blabla?\nb. Of blablabla?\n\n\n\nSharing data tables:\n\n\n\n\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Differentiation introduction</span>"
    ]
  },
  {
    "objectID": "project_2.html",
    "href": "project_2.html",
    "title": "22  Miniproject: maintaining a healthy microbiome",
    "section": "",
    "text": "22.1 Mini description\nMicrobes often form intricate relationships, not only amongst each other, but also with larger organisms from all kingdoms: plants, animals, and fungi. While they often provide useful services, microbes typically evolve much faster than these hosts. What stops a microbe from taking advantage of its host, taking more resources than it provides, or even damaging the host tissue to gain access to even more resources? The latter scenario, we would call a pathogen, and the likelyhood of this transition from occuring could be called the disease pressure.\nUnderstanding the fundamental principles behind disease pressure can help mitigating disease outbreaks. For example, if we understand the conditions under which a microbe is likely to become a pathogen, we can take steps to prevent this from happening.\nTo phrase the above story a little differently: the microbes in our gut or in the soil of our favourite crops, are constantly evolving on a parasitism-mutualism continuum (see Figure 22.1). In this mini project, you will investigate the dynamics of microbiomes evolving on such a continuum. We will particularly focus on how the properties of the host (plant, animals, etc.) shape the likelihood of disease outbreaks. To that end, here are a few key questions to get you started, but you don’t need to focus on each and every one of them at the same time. Plus, more (better!) questions will likely emerge as you work on the project. That’s science.",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Miniproject: maintaining a healthy microbiome</span>"
    ]
  },
  {
    "objectID": "project_2.html#mini-description",
    "href": "project_2.html#mini-description",
    "title": "22  Miniproject: maintaining a healthy microbiome",
    "section": "",
    "text": "Figure 22.1: Parasitism-mutualism continuum of host-associated microbes. Note that this is a cartoon, and that nature is in almost all cases more complicated than this.",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Miniproject: maintaining a healthy microbiome</span>"
    ]
  },
  {
    "objectID": "project_2.html#key-references",
    "href": "project_2.html#key-references",
    "title": "22  Miniproject: maintaining a healthy microbiome",
    "section": "22.2 Key references",
    "text": "22.2 Key references\n\nVan Vliet and Doebeli (2019): a model of self-sacrificing microbes in hosts with different transmission modes.\nKoskella and Bergelson (2020): an opinion piece on host-microbe (co)evolution and levels of selection",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Miniproject: maintaining a healthy microbiome</span>"
    ]
  },
  {
    "objectID": "project_2.html#guiding-questions",
    "href": "project_2.html#guiding-questions",
    "title": "22  Miniproject: maintaining a healthy microbiome",
    "section": "22.3 Guiding questions:",
    "text": "22.3 Guiding questions:\n\nDo motile hosts (e.g. animals) experience different disease pressures than non-motile hosts (e.g. plants)?\nAre mutualistic microbes easier to maintain in short- or long-lived hosts?\nDoes non-local reproduction (e.g. seed/spore dispersal) change these patterns?\nHow does an adaptive immune system (animals) affect the evolution of microbiomes, compared to plants, who don’t have an adaptive immune system?",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Miniproject: maintaining a healthy microbiome</span>"
    ]
  },
  {
    "objectID": "project_2.html#getting-started",
    "href": "project_2.html#getting-started",
    "title": "22  Miniproject: maintaining a healthy microbiome",
    "section": "22.4 Getting started",
    "text": "22.4 Getting started\nMaintaining self-sacrificial microbiomes isn’t easy, as shown by the work of Van Vliet and Doebeli (2019). They show that the evolution of self-sacrificing microbes (which they call “helpers”) is highly sensitive to the host’s longevity and transmission of microbes in between hosts (horizontal transmission). To understand why, start by reading their paper. If you have read it, unfold the text below to see my summary of their methods.\n\n\n\n\n\n\nMy summary of the model by van Vliet et al.\n\n\n\n\n\nThis model studies the maintanance of self-sacrificial “helper” microbes. Here, I will refer to helpers as “allies” (A), as to clearly differentiate it from “hosts” (H). Microbes that are not allies are referred to as neutral (N).\nAllies provide a benefit to their host, while neutral microbes do not. The microbes are modelled with simple ordinary differential equations (ODEs):\n\\[\n\\begin{aligned}\n\\color{#555}{\n\\frac{dN}{dt} =\n\\underbrace{rN}_{\\textrm{Growth N}} -\n\\underbrace{\\delta N(A+N)}_{\\textrm{Density-dependent death}}\n}\\\\\n\\color{green}{\n  \\frac{dA}{dt} =\n  \\underbrace{rA(1-\\gamma)}_{\\textrm{Growth A}} -\n  \\underbrace{\\delta A(A+N)}_{\\textrm{Density-dependent death}}\n}\\\\\n\\end{aligned}\n\\tag{1}\n\\] As you can see, allies grow slower than neutral microbes and are therefore at a competitive disadvantage, and will eventually be outcompeted. To counter-act the loss of allies, van Vliet’s model considers selection at the level of the host. To achieve this, the birth rate of hosts (\\(B_i\\)) depends on the frequency of allies A in the microbiome:\n\\[\nB_i = \\frac{r}{G_H}(1+s_b\\cdot \\frac{A}{A+N})\n\\]\nHere, \\(G_H\\) is a parameter that scales the host generation time w.r.t. the growth rate of microbes (\\(r\\)), with \\(G_H \\gg r\\) ensuring hosts are long-lived compared to microbes. The term \\(s_b\\) is the maximum benefit that hosts get from carrying the ally strain.\nThe death rate of hosts (\\(D_i\\)) increases linearly with the density of hosts at any given time (\\(H(t)\\)), and is given by:\n\\[\nD_i = \\frac{r}{G_H} \\frac{H(t)}{K_H}\n\\]\nWhere \\(H(t)\\) gives the number of hosts at a given time, and \\(K_H\\) denotes the basal carrying capacity in the absence of allies. Note that the true carrying capacity can be higher, as helpers increase the birth rate of hosts.\nWhenever a host reproduces, the microbiome is transmitted vertically to their offspring. The frequency of allies in the offspring is sampled from a normal distribution with mean \\(f_A\\):\n\\[\nf_{offspring}  = \\mathcal{N} (f_{A},\\sigma^2),\n\\\\\\text{with } f_A = \\frac{A}{A+N}\n\\]\nTo avoid negative ally frequencies, this number is truncated such that \\(0&lt;A_{offspring}&lt;1\\). The total density in the newborn is set by another parameter \\(n_0\\). The model by van Vliet also considers “horizontal” transmission of microbiomes, where \\(f_A\\) is not the ally frequency in the parent, but the frequency of allies in the microbiome of a random individual.\nSo far so good with all the math. Now the simulation…\n\nThe simulation loop\n\nThe birth and death rates of all hosts is calculated\nCalculate the probability of a host-level event (birth/death) occurring\nIf an event occurs, draw a random event proportional to its probability.\nExecute the event sampled in step 3\nUpdate all the microbiome ODEs.\n\n\n\n\n\nTo start the project, we will first replicate van Vliet’s results in Python. As a guideline, use my model summary above. I am ready to help where needed, but at this point in the course your experience should go a long way! If the simulation works, see if you can reproduce the following two figures:\n\n\n\n\n\n\n\n\n\n\n\n(a) Allies are maintained within a population of hosts (black line shows the average), despite each individual host (green thinner lines) constantly decreasing in ally types. This can be explained by selection at the level of the host.\n\n\n\n\n\n\n\n\n\n\n\n(b) Allies are not maintained within a population of hosts (black line shows the average) when transmission of microbiomes is horizontal (in between random individuals).\n\n\n\n\n\n\n\nFigure 22.2: Helper maintenance in hosts with different transmission modes",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Miniproject: maintaining a healthy microbiome</span>"
    ]
  },
  {
    "objectID": "project_2.html#extending-the-model",
    "href": "project_2.html#extending-the-model",
    "title": "22  Miniproject: maintaining a healthy microbiome",
    "section": "22.5 Extending the model",
    "text": "22.5 Extending the model\nNow that you have a working base-line model, let’s extend it to address the questions we phrased earlier: how does mobility of the host affect the evolution of microbiomes, and what about non-locally reproducing fungi? How do these host-level traits affect the likelyhood of “disease” outbreaks? Note that so far, we have only discussed “helpers” and “neutral” microbes, but the same principles apply to pathogens but perhaps a little more extreme. For example, the microbes may evolve such high levels of nastiness, that hosts do not only replicate slower, but die. Think about ways to extend the model that allows you to tune these distinctions.\n\n\n\n\nKoskella, Britt, and Joy Bergelson. 2020. “The Study of Host–Microbiome (Co) Evolution Across Levels of Selection.” Philosophical Transactions of the Royal Society B 375 (1808): 20190604.\n\n\nVan Vliet, Simon, and Michael Doebeli. 2019. “The Role of Multilevel Selection in Host Microbiome Evolution.” Proceedings of the National Academy of Sciences 116 (41): 20591–97.",
    "crumbs": [
      "Mini-projects",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Miniproject: maintaining a healthy microbiome</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Crombach, Anton, and Paulien Hogeweg. 2008. “Evolution of\nEvolvability in Gene Regulatory Networks.” PLoS Computational\nBiology 4 (7): e1000112.\n\n\nDriever, Wolfgang, and Christiane Nüsslein-Volhard. 1988. “The\nBicoid Protein Determines Position in the Drosophila Embryo in a\nConcentration-Dependent Manner.” Cell 54 (1): 95–104.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nKoskella, Britt, and Joy Bergelson. 2020. “The Study of\nHost–Microbiome (Co) Evolution Across Levels of Selection.”\nPhilosophical Transactions of the Royal Society B 375 (1808):\n20190604.\n\n\nVan Vliet, Simon, and Michael Doebeli. 2019. “The Role of\nMultilevel Selection in Host Microbiome Evolution.”\nProceedings of the National Academy of Sciences 116 (41):\n20591–97.\n\n\nWolpert, Lewis. 1969. “Positional Information and the Spatial\nPattern of Cellular Differentiation.” Journal of Theoretical\nBiology 25 (1): 1–47.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "answers.html",
    "href": "answers.html",
    "title": "Appendix A — Quarto examples",
    "section": "",
    "text": "A.1 Equations\nHere’s an equation:\n\\[\n\\frac{\\mathrm{d}N}{\\mathrm{d}t} = rN(1 - \\frac{N}{K})\n\\tag{A.1}\\]\nAnd Equation A.1 is a reference to the equation above.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "answers.html#references",
    "href": "answers.html#references",
    "title": "Appendix A — Quarto examples",
    "section": "A.2 References",
    "text": "A.2 References\nSee Knuth (1984) for additional discussion of literate programming.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "answers.html#syntax-highlighting",
    "href": "answers.html#syntax-highlighting",
    "title": "Appendix A — Quarto examples",
    "section": "A.3 Syntax highlighting",
    "text": "A.3 Syntax highlighting\nHere’s some python code:\nimport numpy as np\nnp.random.seed(42)\na = 1 + 2\nb = a + 3\nprint(\"Hello\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "answers.html#visualising-data-r",
    "href": "answers.html#visualising-data-r",
    "title": "Appendix A — Quarto examples",
    "section": "A.4 Visualising data (R)",
    "text": "A.4 Visualising data (R)\nHere’s an interactive plot generated with R:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "answers.html#a-youtube-clip",
    "href": "answers.html#a-youtube-clip",
    "title": "Appendix A — Quarto examples",
    "section": "A.5 A youtube clip:",
    "text": "A.5 A youtube clip:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  },
  {
    "objectID": "answers.html#an-iframe-to-a-different-page-e.g.-my-simulations",
    "href": "answers.html#an-iframe-to-a-different-page-e.g.-my-simulations",
    "title": "Appendix A — Quarto examples",
    "section": "A.6 An ‘iframe’ to a different page (e.g. my simulations)",
    "text": "A.6 An ‘iframe’ to a different page (e.g. my simulations)\n\n\nMermaid\nDiagrams (Mermaid syntax):\n\n\n\n\n\n\nflowchart TB\nA(Models) --&gt; C(\"Analytical (mathematical)\")\nA --&gt; B(\"Numerical (computational)\")\nB --&gt; F(Individual-based model)\nB --&gt; G(Cellular automaton)\nC --&gt; E(Differential equation)\nC --&gt; D(MAPs)\n\n\n\n\nFigure A.1: Types of models\n\n\n\n\n\nWhich can be referred to Figure A.1.\n\n\nCallouts\nCall-outs can organise information and highlight important points.\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\n\n\n\nTip A.1: Cross-Referencing a Tip\n\n\n\nAdd an ID starting with #tip- to reference a tip.\n\n\nSee Tip A.1…\n\n\nHow to format questions/problem sets\n\nExercise A.1 (Test 1) The equation of any straight line, called a linear equation, can be written as:\n\\[\ny = mx + b\n\\tag{A.2}\\]\nRefer to the equation like this Equation A.2 or like Customlabel A.2.\na. Blabla?\nb. Of blablabla?\n\n\n\nSharing data tables:\n\n\n\n\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Quarto examples</span>"
    ]
  }
]